<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <title>AI Docent Bot</title>    
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">    
     <script type="importmap">
        {
            "imports": {
                "three": "https://cdn.jsdelivr.net/npm/three@0.157.0/build/three.module.js",
                "mind-ar": "https://cdn.jsdelivr.net/npm/mind-ar@1.2.5/dist/mindar-image-three.prod.js"
            }
        }
    </script>

    <style>
        /* 1. ë°˜ì‘í˜• ì›¹ì„ ìœ„í•œ CSS ìŠ¤íƒ€ì¼ */
        :root { --sidebar-width: 280px; --header-height: 60px; }
        html, body { margin: 0; padding: 0; width: 100%; height: 100%; overflow: hidden; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif; }
        .view { display: none; width: 100%; height: 100%; flex-direction: column; box-sizing: border-box; }
        .view.active { display: flex; }
        
        /* ì±—ë´‡ ë·° ìŠ¤íƒ€ì¼ */
        #chatbot-view { align-items: center; justify-content: flex-start; background-color: #f0f2f5; }
        #container { display: flex; flex-direction: column; width: 100%; max-width: 800px; height: 100%; }
        #chat-header { display: flex; justify-content: space-between; align-items: center; width: 100%; padding: 10px 20px; box-sizing: border-box; background-color: white; border-bottom: 1px solid #ddd; }
        #transcript { flex-grow: 1; padding: 20px; overflow-y: auto; background-color: #f0f2f5; }
        #input-area { display: flex; gap: 10px; padding: 10px; background-color: white; border-top: 1px solid #ddd; }
        #text-input { flex-grow: 1; padding: 10px; border: 1px solid #ccc; border-radius: 20px; font-size: 1em; }
        .message { margin-bottom: 12px; line-height: 1.5; }
        .user { text-align: right; }
        .user p { background-color: #007bff; color: white; padding: 8px 12px; border-radius: 15px; display: inline-block; max-width: 80%; }
        .ai p { background-color: #e9ecef; color: black; padding: 8px 12px; border-radius: 15px; display: inline-block; max-width: 80%; }
        .ai img { max-width: 100%; border-radius: 8px; margin-top: 10px; }
        
        /* AR ë·° ìŠ¤íƒ€ì¼ */
        #ar-view { position: relative; }
        #ar-scene-container { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }
        .ar-overlay { position: absolute; top: 0; left: 0; right: 0; bottom: 0; z-index: 10; display: flex; flex-direction: column; justify-content: space-between; padding: 20px; box-sizing: border-box; pointer-events: none;}
        .ar-button { padding: 10px 20px; font-size: 1.2em; border-radius: 5px; border: none; background-color: rgba(0,0,0,0.6); color: white; cursor: pointer; pointer-events: all; }
        #ar-description-box { background-color: rgba(0,0,0,0.7); color: white; padding: 15px; border-radius: 10px; max-height: 40%; overflow-y: auto; pointer-events: all; margin: 0 auto 20px auto; max-width: 90%;}
        
        /* ê³µí†µ ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
        .btn { padding: 10px 15px; border-radius: 50%; width: 50px; height: 50px; border: none; color: white; cursor: pointer; font-size: 1.5em; display: flex; align-items: center; justify-content: center; }
        #recordBtn { background-color: #28a745; }
        #recordBtn.recording { background-color: #dc3545; }
        #send-btn { background-color: #007bff; }
        #playBtn { background-color: #17a2b8; }
        .hidden { display: none; }
    </style>
</head>

<body>
    <div id="chatbot-view" class="view active">
        <div id="container">
            <header id="chat-header">
                <h2>Gemini ì±—ë´‡</h2>
                <button id="goto-ar-btn" class="ar-button">ğŸ“· AR ë„ìŠ¨íŠ¸</button>
            </header>
            <main id="transcript"></main>
            <footer id="input-area">
                <button id="recordBtn" class="btn">ğŸ¤</button>
                <input type="text" id="text-input" placeholder="í…ìŠ¤íŠ¸ë¡œ ì§ˆë¬¸í•˜ì„¸ìš”...">
                <button id="send-btn" class="btn">â¤</button>
                <button id="playBtn" class="btn hidden">â–¶ï¸</button>
            </footer>
        </div>
    </div>

    <div id="ar-view" class="view">
        <div id="ar-scene-container"></div>
        <div class="ar-overlay">
            <div style="display: flex; justify-content: space-between;">
                <button id="back-to-chat-btn" class="ar-button">â†©ï¸ ì±—ë´‡ìœ¼ë¡œ</button>
            </div>
            <div id="ar-description-box" class="hidden">
                <p id="ar-text"></p>
                <button id="ar-tts-btn" class="ar-button" style="margin-top: 10px; width: 100%;">ğŸ”Š ìŒì„± ì•ˆë‚´</button>
            </div>
        </div>
    </div>

   <script type="module">

    import * as THREE from 'three';
    import { MindARThree } from 'mind-ar';

    document.addEventListener('DOMContentLoaded', () => {

           // --- ê³µí†µ ìš”ì†Œ ë° ìƒíƒœ ë³€ìˆ˜ ---
            const chatbotView = document.getElementById('chatbot-view'), arView = document.getElementById('ar-view');
            const gotoArBtn = document.getElementById('goto-ar-btn'), backToChatBtn = document.getElementById('back-to-chat-btn');
            const recordBtn = document.getElementById('recordBtn'), playBtn = document.getElementById('playBtn');
            const transcriptDiv = document.getElementById('transcript'), textInput = document.getElementById('text-input'), sendBtn = document.getElementById('send-btn');
            const arSceneContainer = document.getElementById('ar-scene-container'), descriptionBox = document.getElementById('ar-description-box');
            const arText = document.getElementById('ar-text'), arTtsBtn = document.getElementById('ar-tts-btn');

            let pdfContent = [], arStarted = false, audioContext;
            let socket, mediaRecorder, audioChunks = [], isRecording = false;
            let lastInputWasVoice = false, currentAudioSource = null;


        gotoArBtn.onclick = () => {
            chatbotView.classList.remove('active');
            arView.classList.add('active');
            if (!arStarted) {
                startAR();
                arStarted = true;
            }
        };
        backToChatBtn.onclick = () => {
            arView.classList.remove('active');
            chatbotView.classList.add('active');
        };

        // --- 5. AR ê¸°ëŠ¥ ë¡œì§ ---
 
        async function startAR() {
                try {
                    const response = await fetch('/api/pdf-content');
                    pdfContent = await response.json();
                    
                    const mindarThree = new MindARThree({
                        container: arSceneContainer,
                        imageTargetSrc: '/static/targets.mind',
                    });
                    const {renderer, scene, camera} = mindarThree;
                    
                    await mindarThree.start();
                    renderer.setAnimationLoop(() => renderer.render(scene, camera));
                    
                    mindarThree.on('targetFound', event => {
                        const targetIndex = event.target.targetIndex;
                        const foundImage = pdfContent.flatMap(p => p.images)[targetIndex];
                        if (foundImage) {
                            const foundPage = pdfContent.find(p => p.images.includes(foundImage));
                            if (foundPage) { arText.textContent = foundPage.text; descriptionBox.classList.remove('hidden'); }
                        }
                    });
                    mindarThree.on('targetLost', () => descriptionBox.classList.add('hidden'));
                } catch(e) { console.error("AR ì‹œì‘ ì˜¤ë¥˜:", e); alert("AR ê¸°ëŠ¥ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); }
            }
        
        arTtsBtn.onclick = async () => {
            const text = arText.textContent;
            if (!text) return;
            const response = await fetch('/api/tts', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ text_to_speak: text })
            });
            const data = await response.json();
            if (data.audio) {
                const audio = new Audio("data:audio/mp3;base64," + data.audio);
                audio.play();
            }
        };


        function isIOS() { return /iPhone|iPad|iPod/.test(navigator.userAgent) && !window.MSStream; }
        function addLog(type, text) { const p = document.createElement('p'); p.className = 'message ' + type; p.innerHTML = type === 'user_text' ? `<strong>ğŸ‘¤ ë‚˜:</strong> ${text}` : type === 'ai_text' ? `<strong>ğŸ¤– DocentBot:</strong> ${text}` : `<span class="system">${text}</span>`; transcriptDiv.appendChild(p); transcriptDiv.scrollTop = transcriptDiv.scrollHeight; }
        function setInputs(enabled) { recordBtn.disabled = !enabled; sendBtn.disabled = !enabled; textInput.disabled = !enabled; }

        function connectWebSocket() {
            const socketURL = `${window.location.protocol === 'https:' ? 'wss:' : 'ws:'}//${window.location.host}/ws`;
            socket = new WebSocket(socketURL);
            socket.onopen = () => { setInputs(true); addLog('system', 'ì±—ë´‡ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.'); };
            socket.onmessage = async (event) => {
                if (event.data instanceof Blob) {
                    const audioBlob = event.data;
                    const shouldAutoplay = lastInputWasVoice && !isIOS();
                    if (shouldAutoplay) {
                        playReceivedAudio(audioBlob);
                    } else {
                        playBtn.onclick = () => playReceivedAudio(audioBlob);
                        playBtn.classList.remove('hidden');
                        setInputs(true);
                    }
                } else {
                    const message = JSON.parse(event.data);


            // âœ¨ ì´ë¯¸ì§€ ë©”ì‹œì§€ íƒ€ì… ì²˜ë¦¬
                    if (message.type === 'ai_image') {
                       const img = document.createElement('img');
                       img.src = message.url;
                       img.style.maxWidth = '100%';
                       img.style.borderRadius = '8px';
                       img.style.marginTop = '10px';
                       transcriptDiv.appendChild(img);
                       transcriptDiv.scrollTop = transcriptDiv.scrollHeight;
                    } else {
                // ê¸°ì¡´ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬
 //                      addMessageToTranscript(message.type, message.data);
                      addLog(message.type, message.data);
 //                     if (message.type === 'error') { setInputs(false); }
                    }
                   
                }
            };
            socket.onclose = () => { addLog('system', 'ì„œë²„ ì—°ê²°ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'); setInputs(false); };
        }

        function sendTextMessage() {
            const text = textInput.value.trim();
            if (!text || socket?.readyState !== WebSocket.OPEN) return;
            lastInputWasVoice = false;
            socket.send(JSON.stringify({ type: 'text', data: text }));
            addLog('user_text', text);
            textInput.value = "";
            setInputs(false);
            playBtn.classList.add('hidden');
        }

        async function startRecording() {
            lastInputWasVoice = true;
            setInputs(false); recordBtn.disabled = false;
            playBtn.classList.add('hidden');
            try {
                if (!audioContext) audioContext = new (window.AudioContext || window.webkitAudioContext)();
                if (audioContext.state === 'suspended') await audioContext.resume();
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' });
                audioChunks = [];
                mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
                mediaRecorder.onstop = () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    const reader = new FileReader();
                    reader.readAsDataURL(audioBlob);
                    reader.onloadend = () => {
                        const base64Audio = reader.result.split(',')[1];
                        if (socket?.readyState === WebSocket.OPEN) socket.send(JSON.stringify({ type: 'audio', data: base64Audio }));
                    };
                };
                mediaRecorder.start();
                isRecording = true;
                recordBtn.textContent = "ğŸ™ï¸";
                recordBtn.classList.add('recording');
            } catch (err) { alert("ë§ˆì´í¬ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); setInputs(true); }
        }

        function stopRecording() { if (mediaRecorder) mediaRecorder.stop(); isRecording = false; recordBtn.textContent = "ğŸ¤"; recordBtn.classList.remove('recording'); setInputs(false); }
        
        async function playReceivedAudio(audioBlob) {
            if (currentAudioSource) currentAudioSource.stop();
            if (!audioBlob) return;
            
            playBtn.classList.remove('hidden');
            playBtn.textContent = "â¸ï¸ ë“£ê¸° ì¤‘ì§€";
            playBtn.onclick = stopCurrentAudio;
            setInputs(false);

            if (!audioContext) audioContext = new (window.AudioContext || window.webkitAudioContext)();
            if (audioContext.state === 'suspended') await audioContext.resume();
            
            try {
                const arrayBuffer = await audioBlob.arrayBuffer();
                const decodedBuffer = await audioContext.decodeAudioData(arrayBuffer);
                currentAudioSource = audioContext.createBufferSource();
                currentAudioSource.buffer = decodedBuffer;
                currentAudioSource.connect(audioContext.destination);
                currentAudioSource.start(0);
                currentAudioSource.onended = () => { if (currentAudioSource) stopCurrentAudio(false); };
            } catch(e) { console.error("ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜:", e); stopCurrentAudio(false); }
        }

        function stopCurrentAudio(isManualStop = true) {
            if (currentAudioSource) {
                currentAudioSource.onended = null;
                if(isManualStop) currentAudioSource.stop();
                currentAudioSource = null;
            }
            playBtn.classList.add('hidden');
            playBtn.textContent = "â–¶ï¸ ë‹µë³€ ë“£ê¸°";
            setInputs(true);
        }

        recordBtn.onclick = () => isRecording ? stopRecording() : startRecording();
        sendBtn.onclick = sendTextMessage;
        textInput.addEventListener('keyup', e => { if (e.key === 'Enter') sendTextMessage(); });
        
        connectWebSocket();
    });
    </script>
</body>
</html>