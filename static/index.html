<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Docent Bot</title>
    <style>
      body{
        font-family:sans-serif;
        display:flex;
        flex-direction:column;
        align-items:center;
        justify-content:flex-start;
        height:100vh;
        margin:0;
        background-color:#f0f2f5;
        padding-top:20px;
        box-sizing:border-box
        }

        #container{
            width:90%;
            max-width:700px;
            text-align:center
            }
        #status{
            font-size:1.2em;
            color:#333;
            margin-bottom:20px;
            background-color:#e9ecef;
            padding:10px 20px;
            border-radius:20px;
            text-align:center;
            font-weight:700
            }

        #recordBtn,#playBtn{
            font-size:1.5em;
            padding:20px 40px;
            border-radius:50px;
            border:none;
            cursor:pointer;
            color:#fff;
            transition:background-color .3s;
            margin-bottom:20px
        }
        #recordBtn{background-color:#28a745}

        #recordBtn.recording{
            background-color:#dc3545
            }
        #recordBtn:disabled{
            background-color:#6c757d;
            cursor:not-allowed
            }
        /* ✨ 재생 버튼 스타일 추가 */
        #playBtn { background-color: #007bff; }

        #transcript{
            text-align:left;
            width:100%;
            background-color:#fff;
            border-radius:8px;
            padding:20px;
            box-shadow:0 2px 4px rgba(0,0,0,.1);
            height:50vh;
            overflow-y:auto;
            box-sizing:border-box
            }
        .message{
            margin-bottom:12px;
            line-height:1.5
        }
        .user{
            color:#005a9c;
            font-weight:700
        }
        .ai{
            color:#444
        }
        
        .hidden{
            display:none
        }
    </style>
</head>
<body>
    <div id="container">
        <h1>AI Docent Bot</h1>
        <div id="status">서버에 연결 중...</div>
        <button id="recordBtn" disabled>🎤 질문 Start</button>
        <button id="playBtn" class="hidden">▶️ 답변 듣기</button> 
        <div id="transcript"></div>
    </div>
    
    <script>
    const statusDiv = document.getElementById('status');
    const recordBtn = document.getElementById('recordBtn');
    const playBtn = document.getElementById('playBtn');
    const transcriptDiv = document.getElementById('transcript');
    
    let socket;
    let mediaRecorder;
    let audioChunks = [];
    let isRecording = false;

    let audioContext;
    let lastReceivedAudioBlob = null; // iOS에서 사용할 오디오 Blob

     // ✨ 1. iOS 기기인지 판별하는 헬퍼 함수
    function isIOS() {
        return /iPhone|iPad|iPod/.test(navigator.userAgent) && !window.MSStream;
    }

    // 페이지 로드 시 웹소켓 연결 시작
    connectWebSocket();

    function connectWebSocket() {
        const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
        const host = window.location.host;
        const socketURL = `${protocol}//${host}/ws`;
        socket = new WebSocket(socketURL);

        socket.onopen = () => {
            statusDiv.textContent = "녹음 버튼을 누르고 말씀하세요.";
            recordBtn.disabled = false;
            transcriptDiv.innerHTML = "<p>챗봇이 준비되었습니다.</p>";
        };

        // ✨ 2. 기기별로 분기 처리하는 onmessage 로직
        socket.onmessage = async (event) => {
            if (event.data instanceof Blob) {
                console.log("서버로부터 음성(Blob) 데이터를 받았습니다.");
                
                if (isIOS()) {
                    // --- iOS 기기일 경우: '답변 듣기' 버튼 표시 ---
                    console.log("iOS 기기 감지됨. 재생 버튼을 표시합니다.");
                    lastReceivedAudioBlob = event.data; // Blob을 나중에 사용하기 위해 저장
                    
                    statusDiv.textContent = "답변이 도착했습니다. 듣기 버튼을 눌러주세요.";
                    recordBtn.disabled = true;
                    playBtn.classList.remove('hidden');

                } else {
                    // --- PC, 안드로이드 등 다른 기기일 경우: 자동 재생 ---
                    console.log("Non-iOS 기기 감지됨. 자동 재생합니다.");
                    const audioUrl = URL.createObjectURL(event.data);
                    const audio = new Audio(audioUrl);
                    
                    statusDiv.textContent = "답변을 재생합니다...";
                    recordBtn.disabled = true; // 재생 중에는 버튼 비활성화
                    audio.play();
                    
                    // 재생이 끝나면 녹음 버튼을 다시 활성화
                    audio.onended = () => {
                        console.log("음성 재생 완료 (자동재생)");
                        statusDiv.textContent = "녹음 버튼을 누르고 말씀하세요.";
                        recordBtn.disabled = false;
                    };
                }

            } else {
                // 텍스트 메시지 처리
                const message = JSON.parse(event.data);
                addMessageToTranscript(message.type, message.data);
            }
        };
        
        socket.onclose = () => { /* 이전과 동일 */ };
    }
    
    // ✨ 3. 재생 버튼 클릭 핸들러 (iOS에서만 사용됨)
    playBtn.onclick = async () => {
        if (!lastReceivedAudioBlob) return;
        if (!audioContext) { audioContext = new (window.AudioContext || window.webkitAudioContext)(); }
        if (audioContext.state === 'suspended') await audioContext.resume();

        try {
            const arrayBuffer = await lastReceivedAudioBlob.arrayBuffer();
            const decodedBuffer = await audioContext.decodeAudioData(arrayBuffer);

            const source = audioContext.createBufferSource();
            source.buffer = decodedBuffer;
            source.connect(audioContext.destination);
            source.start(0);

            statusDiv.textContent = "답변을 재생합니다...";
            playBtn.classList.add('hidden');

            source.onended = () => {
                console.log("음성 재생 완료 (iOS)");
                statusDiv.textContent = "녹음 버튼을 누르고 말씀하세요.";
                recordBtn.disabled = false;
            };
        } catch (e) {
            console.error("오디오 재생 오류:", e);
            alert("오디오 재생에 실패했습니다.");
            recordBtn.disabled = false;
        } finally {
            lastReceivedAudioBlob = null;
        }
    };


    // 나머지 함수들은 모두 이전 답변과 동일합니다.
//    async function startRecording() {
//        try {
//            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
//            mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' });
//            mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
//            mediaRecorder.onstop = () => {
//                const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
//                if (socket?.readyState === WebSocket.OPEN) socket.send(audioBlob);
//                audioChunks = [];
//            };
//            mediaRecorder.start();
//            isRecording = true;
//            transcriptDiv.innerHTML = "";
//            statusDiv.textContent = "말씀하세요...";
//            recordBtn.textContent = "🎙️ 녹음 중지";
//            recordBtn.classList.add('recording');
//            playBtn.classList.add('hidden');
//        } catch (err) { alert("마이크에 접근할 수 없습니다."); }
//   }

//    function stopRecording() {
//        if (mediaRecorder) mediaRecorder.stop();
//        isRecording = false;
//        statusDiv.textContent = "음성을 처리 중입니다...";
//        recordBtn.textContent = "🎤 녹음 시작";
//        recordBtn.classList.remove('recording');
//        recordBtn.disabled = true;
//    }

//    function addMessageToTranscript(sender, text) {
//        const p = document.createElement('p');
//        p.classList.add('message');
//        p.innerHTML = `<span class="${sender === 'user' ? 'user' : 'ai'}">${sender === 'user' ? '👤 나:' : '🤖 Gemini:'}</span> ${text}`;
//        transcriptDiv.appendChild(p);
//        transcriptDiv.scrollTop = transcriptDiv.scrollHeight;
//    }

    recordBtn.onclick = () => { isRecording ? stopRecording() : startRecording(); };


    function addMessageToTranscript(sender, text) { const p = document.createElement('p'); p.classList.add('message'); p.innerHTML = `<span class="${sender === 'user' ? 'user' : 'ai'}">${sender === 'user' ? '👤 나:' : '🤖 Gemini:'}</span> ${text}`; transcriptDiv.appendChild(p); transcriptDiv.scrollTop = transcriptDiv.scrollHeight; }
    function stopRecording() { if (mediaRecorder) mediaRecorder.stop(); isRecording = false; statusDiv.textContent = "음성을 처리 중입니다..."; recordBtn.textContent = "🎤 녹음 시작"; recordBtn.classList.remove('recording'); recordBtn.disabled = true; }
    async function startRecording() { if (!audioContext) { audioContext = new (window.AudioContext || window.webkitAudioContext)(); if (audioContext.state === 'suspended') await audioContext.resume(); } try { const stream = await navigator.mediaDevices.getUserMedia({ audio: true }); mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' }); mediaRecorder.ondataavailable = e => audioChunks.push(e.data); mediaRecorder.onstop = () => { const audioBlob = new Blob(audioChunks, { type: 'audio/webm' }); if (socket?.readyState === WebSocket.OPEN) socket.send(audioBlob); audioChunks = []; }; mediaRecorder.start(); isRecording = true; transcriptDiv.innerHTML = ""; statusDiv.textContent = "말씀하세요..."; recordBtn.textContent = "🎙️ 녹음 중지"; recordBtn.classList.add('recording'); playBtn.classList.add('hidden'); } catch (err) { alert("마이크에 접근할 수 없습니다."); } }


</script>
</body>
</html>