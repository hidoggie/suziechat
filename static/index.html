<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ìŒì„± ì±—ë´‡ ì„œë¹„ìŠ¤</title>
    <style>
        /* CSSëŠ” ì´ì „ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€ */
        body { font-family: sans-serif; display: flex; flex-direction: column; align-items: center; justify-content: flex-start; height: 100vh; margin: 0; background-color: #f0f2f5; padding-top: 20px; }
        #container { width: 90%; max-width: 700px; }
        #status { font-size: 1.2em; color: #fff; margin-bottom: 20px; background-color: #555; padding: 10px 20px; border-radius: 20px; text-align: center; transition: background-color 0.3s; }
        #status.listening { background-color: #28a745; }
        #status.speaking { background-color: #007bff; }
        #status.processing { background-color: #ffc107; color: #333; }
        #transcript { margin-top: 20px; width: 100%; background-color: white; border-radius: 8px; padding: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); min-height: 300px; max-height: 60vh; overflow-y: auto;}
        .message { margin-bottom: 12px; line-height: 1.5; }
        .user { color: #005A9C; font-weight: bold; }
        .ai { color: #444; }

        #overlay {
            position: fixed; /* í™”ë©´ ì „ì²´ë¥¼ ë®ë„ë¡ ê³ ì • */
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0, 0, 0, 0.7); /* ë°˜íˆ¬ëª… ê²€ì€ìƒ‰ ë°°ê²½ */
            display: flex;
            justify-content: center;
            align-items: center;
            z-index: 1000; /* ë‹¤ë¥¸ ìš”ì†Œë“¤ ìœ„ì— í‘œì‹œ */
        }
        #overlay-text {
            color: white;
            font-size: 2em;
            text-align: center;
            padding: 20px;
        }
        .hidden {
            visibility: hidden; /* í‰ì†Œì—ëŠ” ìˆ¨ê²¨ë‘  */
        }

    </style>
</head>
<body>
    <div id="container">
        <h1>ìŒì„± ì±—ë´‡ ì„œë¹„ìŠ¤</h1>
        <div id="status">ì—°ê²° ëŒ€ê¸° ì¤‘...</div>
        <div id="transcript">
            <p>ì„œë²„ì— ì—°ê²°ë˜ë©´ ìë™ìœ¼ë¡œ ìŒì„± ê°ì§€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.</p>
        </div>
    </div>

    <div id="overlay" class="hidden">
        <div id="overlay-text">
            ëŒ€í™”ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.<br><br>ì´ ì°½ì„ ë‹«ì•„ì£¼ì„¸ìš”.
        </div>
    </div>

    <script>
        const statusDiv = document.getElementById('status');
        const transcriptDiv = document.getElementById('transcript');
        const overlay = document.getElementById('overlay'); // ì˜¤ë²„ë ˆì´ ìš”ì†Œ ê°€ì ¸ì˜¤ê¸°
        let socket;

        // ì—°ê²°ì´ í•œ ë²ˆì´ë¼ë„ ì„±ê³µí–ˆëŠ”ì§€ ê¸°ì–µí•˜ëŠ” 'ê¹ƒë°œ' ë³€ìˆ˜.
        // ì´ ë³€ìˆ˜ ë•ë¶„ì— ì´ˆê¸° ë¡œë”© ì‹œ ì—°ê²°ì— ì‹¤íŒ¨í•´ë„ ì¢…ë£Œ ì˜¤ë²„ë ˆì´ê°€ ëœ¨ì§€ ì•ŠìŠµë‹ˆë‹¤.
        let connectionEstablished = false;

        const VAD_CONFIG = {
            SILENCE_THRESHOLD: 0.01,
            SILENCE_DURATION: 1.5,
            SAMPLE_RATE: 16000, // ë°±ì—”ë“œì™€ ìƒ˜í”Œë§ ë ˆì´íŠ¸ í†µì¼
        };

        let audioContext, mediaStream, mediaStreamSource, scriptProcessor;
        let isSpeaking = false;
        let silenceStartTime = 0;
        let audioBuffer = [];

        function connectWebSocket() {
  //          socket = new WebSocket("ws://127.0.0.1:8000/ws");

            console.log("WebSocket ì—°ê²° ì‹œë„...");
            
            // âœ¨âœ¨âœ¨ ìµœì¢… ìˆ˜ì •ëœ ë¶€ë¶„ âœ¨âœ¨âœ¨
            // 1. í˜„ì¬ í˜ì´ì§€ì˜ í”„ë¡œí† ì½œ(http/https)ì„ í™•ì¸í•©ë‹ˆë‹¤.
            const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
            // 2. í˜„ì¬ í˜ì´ì§€ì˜ í˜¸ìŠ¤íŠ¸ ì£¼ì†Œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
            const host = window.location.host;
            // 3. ë™ì ìœ¼ë¡œ ì›¹ì†Œì¼“ ì£¼ì†Œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
            const socketURL = `${protocol}//${host}/ws`;

            console.log(`ì—°ê²°í•  ì›¹ì†Œì¼“ ì£¼ì†Œ: ${socketURL}`);
            socket = new WebSocket(socketURL);
            // socket = new WebSocket("wss://https://suziechat.onrender.com/ws"); // ì§ì ‘ ì£¼ì†Œë¥¼ ì…ë ¥í•´ë„ ë©ë‹ˆë‹¤.


            socket.onopen = () => {
                // ì—°ê²°ì— ì„±ê³µí•˜ë©´ 'ê¹ƒë°œ'ì„ trueë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
                connectionEstablished = true;

                statusDiv.textContent = "ë“£ê³  ìˆìŠµë‹ˆë‹¤...";
                statusDiv.className = 'listening';
                startVoiceActivityDetection();
            };
            socket.onmessage = (event) => {
                if (event.data instanceof Blob) {
                    const audioUrl = URL.createObjectURL(event.data);
                    const audio = new Audio(audioUrl);
                    audio.play();
                    audio.onended = () => {
                        statusDiv.textContent = "ë“£ê³  ìˆìŠµë‹ˆë‹¤...";
                        statusDiv.className = 'listening';
                    };
                } else {
                    const message = JSON.parse(event.data);
                    const p = document.createElement('p');
                    p.classList.add('message');
                    if (message.type === 'user_text') {
                        p.innerHTML = `<span class="user">ğŸ‘¤ ë‚˜:</span> ${message.data}`;
                    } else if (message.type === 'ai_text') {
                        p.innerHTML = `<span class="ai">ğŸ¤– Gemini:</span> ${message.data}`;
                    }
                    transcriptDiv.appendChild(p);
                    transcriptDiv.scrollTop = transcriptDiv.scrollHeight;
                }
            };
            socket.onclose = () => {
                stopVoiceActivityDetection();

                // ì—°ê²°ì´ í•œ ë²ˆì´ë¼ë„ ì„±ê³µí–ˆë‹¤ê°€(true) ëŠì–´ì§„ ê²½ìš°ì—ë§Œ ì¢…ë£Œ ì˜¤ë²„ë ˆì´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
                if (connectionEstablished) {
                    overlay.classList.remove('hidden');
                } else {
                    // í˜ì´ì§€ ë¡œë”© ì‹œ ì²˜ìŒë¶€í„° ì—°ê²°ì— ì‹¤íŒ¨í•œ ê²½ìš°, ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
                    statusDiv.textContent = "ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°±ì—”ë“œ ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.";
                }


             //   statusDiv.textContent = "ì„¸ì…˜ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.";
                statusDiv.className = '';
                stopVoiceActivityDetection();

                // ì˜¤ë²„ë ˆì´ë¥¼ í‘œì‹œí•˜ì—¬ ì¢…ë£Œ ìƒíƒœë¥¼ ëª…í™•íˆ í•¨
                overlay.classList.remove('hidden');
            };

            socket.onerror = (error) => {
                console.error("WebSocket ì˜¤ë¥˜:", error);
                statusDiv.textContent = "ì—°ê²° ì˜¤ë¥˜ ë°œìƒ!";
                connectionEstablished = false; // ì—ëŸ¬ ë°œìƒ ì‹œ ì—°ê²° ì‹¤íŒ¨ë¡œ ê°„ì£¼
            };

        }

        async function startVoiceActivityDetection() {
            try {
                mediaStream = await navigator.mediaDevices.getUserMedia({ audio: { sampleRate: VAD_CONFIG.SAMPLE_RATE, channelCount: 1 } });
                audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: VAD_CONFIG.SAMPLE_RATE });
                scriptProcessor = audioContext.createScriptProcessor(4096, 1, 1);
                mediaStreamSource = audioContext.createMediaStreamSource(mediaStream);

                scriptProcessor.onaudioprocess = (event) => {
                    const inputData = event.inputBuffer.getChannelData(0);
                    const rms = Math.sqrt(inputData.reduce((sum, val) => sum + val * val, 0) / inputData.length);

                    if (isSpeaking) {
                        audioBuffer.push(new Float32Array(inputData));
                        if (rms < VAD_CONFIG.SILENCE_THRESHOLD) {
                            if (silenceStartTime === 0) silenceStartTime = Date.now();
                            if ((Date.now() - silenceStartTime) / 1000 >= VAD_CONFIG.SILENCE_DURATION) {
                                processAndSendAudio();
                                isSpeaking = false;
                            }
                        } else {
                            silenceStartTime = 0;
                        }
                    } else if (rms > VAD_CONFIG.SILENCE_THRESHOLD) {
                        isSpeaking = true;
                        silenceStartTime = 0;
                        audioBuffer = [];
                        transcriptDiv.innerHTML = "";
                        statusDiv.textContent = "ìŒì„± ê°ì§€ë¨! ë§í•˜ì„¸ìš”...";
                        statusDiv.className = 'speaking';
                    }
                };
                mediaStreamSource.connect(scriptProcessor);
                scriptProcessor.connect(audioContext.destination);
            } catch (err) {
                alert("ë§ˆì´í¬ ì ‘ê·¼ ì˜¤ë¥˜: " + err);
            }
        }

        function stopVoiceActivityDetection() {
            if (mediaStream) mediaStream.getTracks().forEach(track => track.stop());
            if (audioContext && audioContext.state !== 'closed') audioContext.close();
        }

        function processAndSendAudio() {
            statusDiv.textContent = "ìŒì„± ì²˜ë¦¬ ì¤‘...";
            statusDiv.className = 'processing';
            const wavBlob = pcmToWavBlob(audioBuffer, VAD_CONFIG.SAMPLE_RATE);
            if (socket && socket.readyState === WebSocket.OPEN) {
                socket.send(wavBlob);
            }
        }
        
        // âœ¨âœ¨âœ¨ Raw PCM ë°ì´í„°ë¥¼ WAV í¬ë§· Blobìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜ âœ¨âœ¨âœ¨
        function pcmToWavBlob(pcmBuffers, sampleRate) {
            let totalLength = pcmBuffers.reduce((sum, arr) => sum + arr.length, 0);
            let buffer = new ArrayBuffer(44 + totalLength * 2);
            let view = new DataView(buffer);
            
            // WAV í—¤ë” ì‘ì„±
            writeString(view, 0, 'RIFF');
            view.setUint32(4, 36 + totalLength * 2, true);
            writeString(view, 8, 'WAVE');
            writeString(view, 12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, 1, true); // channel
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 2, true);
            view.setUint16(32, 2, true);
            view.setUint16(34, 16, true);
            writeString(view, 36, 'data');
            view.setUint32(40, totalLength * 2, true);

            // PCM ë°ì´í„° ì‘ì„±
            let offset = 44;
            for (const pcmData of pcmBuffers) {
                for (let i = 0; i < pcmData.length; i++, offset += 2) {
                    let s = Math.max(-1, Math.min(1, pcmData[i]));
                    view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
                }
            }
            return new Blob([view], { type: 'audio/wav' });
        }
        
        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }

        connectWebSocket();
    </script>
</body>
</html>
