<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <title>Gemini ìŒì„± ì±—ë´‡</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style> /* ì´ì „ê³¼ ë™ì¼í•œ CSS */ </style>
</head>
<body>
    <div id="container">
        <h1>ìŒì„±/í…ìŠ¤íŠ¸ ì±—ë´‡</h1>
        <div id="status">ì„œë²„ ì—°ê²° ì¤‘...</div>
        <div id="transcript"></div>
        <div id="input-area">
            <button id="recordBtn" disabled>ğŸ¤</button>
            <input type="text" id="text-input" placeholder="í…ìŠ¤íŠ¸ë¡œ ì§ˆë¬¸í•˜ì„¸ìš”..." disabled>
            <button id="send-btn" disabled>ì „ì†¡</button>
        </div>
        <button id="playBtn" class="hidden" style="margin-top: 10px;">â–¶ï¸ ë‹µë³€ ë“£ê¸°</button>
    </div>

<script>
    // --- ìš”ì†Œ ê°€ì ¸ì˜¤ê¸° ---
    const statusDiv = document.getElementById('status');
    const recordBtn = document.getElementById('recordBtn');
    const playBtn = document.getElementById('playBtn');
    const transcriptDiv = document.getElementById('transcript');
    const textInput = document.getElementById('text-input');
    const sendBtn = document.getElementById('send-btn');
    
    // --- ìƒíƒœ ë³€ìˆ˜ ---
    let socket;
    let mediaRecorder;
    let audioChunks = [];
    let isRecording = false;
    let lastInputWasVoice = false;
    let audioContext;
    let lastReceivedAudioBlob = null;

    // --- í—¬í¼ í•¨ìˆ˜ ---
    function isIOS() { return /iPhone|iPad|iPod/.test(navigator.userAgent) && !window.MSStream; }
    
    function addMessageToTranscript(type, text) {
        const p = document.createElement('p');
        p.classList.add('message');
        if (type === 'user_text') {
            p.innerHTML = `<span class="user">ğŸ‘¤ ë‚˜:</span> ${text}`;
        } else if (type === 'ai_text') {
            p.innerHTML = `<span class="ai">ğŸ¤– Gemini:</span> ${text}`;
        } else { // 'system' ë©”ì‹œì§€ ë“±
            p.innerHTML = `<span class="system" style="color: #6c757d;">${text}</span>`;
        }
        transcriptDiv.appendChild(p);
        transcriptDiv.scrollTop = transcriptDiv.scrollHeight;
    }

    function disableInputs() { recordBtn.disabled = true; sendBtn.disabled = true; textInput.disabled = true; }
    function enableInputs() { recordBtn.disabled = false; sendBtn.disabled = false; textInput.disabled = false; }

    // --- ì›¹ì†Œì¼“ ë¡œì§ ---
    function connectWebSocket() {
        const socketURL = `${window.location.protocol === 'https:' ? 'wss:' : 'ws:'}//${window.location.host}/ws`;
        socket = new WebSocket(socketURL);

        socket.onopen = () => {
            statusDiv.textContent = "ì…ë ¥ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”.";
            enableInputs();
            addMessageToTranscript('system', 'ì±—ë´‡ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.');
        };

        socket.onmessage = async (event) => {
            if (event.data instanceof Blob) {
                lastReceivedAudioBlob = event.data;
                const shouldAutoplay = lastInputWasVoice && !isIOS();
                
                if (shouldAutoplay) {
                    playReceivedAudio(true); // ìë™ ì¬ìƒ
                } else {
                    playBtn.classList.remove('hidden'); // ë²„íŠ¼ í‘œì‹œ
                    enableInputs(); // âœ¨ í…ìŠ¤íŠ¸ ì…ë ¥ í›„ì—ë„ ë°”ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì„ í•  ìˆ˜ ìˆë„ë¡ ë²„íŠ¼ í™œì„±í™”
                }
            } else {
                const message = JSON.parse(event.data);
                // âœ¨ 1. ëˆ„ë½ë˜ì—ˆë˜ ë©”ì‹œì§€ í‘œì‹œ ê¸°ëŠ¥ ì¶”ê°€
                addMessageToTranscript(message.type, message.data);
            }
        };

        socket.onclose = () => { addMessageToTranscript('system', 'ì„œë²„ ì—°ê²°ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'); disableInputs(); statusDiv.textContent = 'ì—°ê²° ì¢…ë£Œë¨'; };
        socket.onerror = () => { addMessageToTranscript('system', 'ì—°ê²° ì˜¤ë¥˜ ë°œìƒ!'); };
    }

    // --- ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ---
    recordBtn.onclick = () => isRecording ? stopRecording() : startRecording();
    sendBtn.onclick = sendTextMessage;
    textInput.addEventListener('keyup', e => { if (e.key === 'Enter') sendTextMessage(); });
    playBtn.onclick = () => playReceivedAudio(false);

    function sendTextMessage() {
        const text = textInput.value.trim();
        if (!text || !socket || socket.readyState !== WebSocket.OPEN) return;
        
        lastInputWasVoice = false;
        socket.send(JSON.stringify({ type: 'text', data: text }));
        addMessageToTranscript('user_text', text);
        textInput.value = "";
        disableInputs();
        playBtn.classList.add('hidden'); // ìƒˆ ì§ˆë¬¸ ì‹œ ì´ì „ ì¬ìƒ ë²„íŠ¼ ìˆ¨ê¸°ê¸°
    }

    async function startRecording() {
        lastInputWasVoice = true;
        disableInputs();
        recordBtn.disabled = false; // ë…¹ìŒ ì¤‘ì§€ ë²„íŠ¼ì€ í™œì„±í™”
        playBtn.classList.add('hidden'); // ìƒˆ ì§ˆë¬¸ ì‹œ ì´ì „ ì¬ìƒ ë²„íŠ¼ ìˆ¨ê¸°ê¸°
        transcriptDiv.innerHTML = "";
        
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' });
            audioChunks = [];
            mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
            mediaRecorder.onstop = () => {
                const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                const reader = new FileReader();
                reader.readAsDataURL(audioBlob);
                reader.onloadend = () => {
                    const base64Audio = reader.result.split(',')[1];
                    if (socket?.readyState === WebSocket.OPEN) {
                        socket.send(JSON.stringify({ type: 'audio', data: base64Audio }));
                    }
                };
            };
            mediaRecorder.start();
            isRecording = true;
            statusDiv.textContent = "ë§ì”€í•˜ì„¸ìš”...";
            recordBtn.textContent = "ğŸ™ï¸ ë…¹ìŒ ì¤‘ì§€";
            recordBtn.classList.add('recording');
        } catch (err) {
            alert("ë§ˆì´í¬ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
            enableInputs();
        }
    }

    function stopRecording() {
        if (mediaRecorder) mediaRecorder.stop();
        isRecording = false;
        statusDiv.textContent = "ìŒì„±ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤...";
        recordBtn.textContent = "ğŸ¤ ë…¹ìŒ ì‹œì‘";
        recordBtn.classList.remove('recording');
        disableInputs();
    }
    
    // âœ¨ 2. UX ê°œì„ ì„ ìœ„í•œ ì¬ìƒ ë¡œì§ ìˆ˜ì •
    async function playReceivedAudio(isAutoplay = false) {
        if (!lastReceivedAudioBlob) return;
        if (!isAutoplay) playBtn.classList.add('hidden'); // ë²„íŠ¼ í´ë¦­ ì‹œ ë°”ë¡œ ìˆ¨ê¸°ê¸°

        statusDiv.textContent = "ë‹µë³€ì„ ì¬ìƒí•©ë‹ˆë‹¤...";
        
        if (!audioContext) audioContext = new (window.AudioContext || window.webkitAudioContext)();
        if (audioContext.state === 'suspended') await audioContext.resume();
        
        try {
            const arrayBuffer = await lastReceivedAudioBlob.arrayBuffer();
            const decodedBuffer = await audioContext.decodeAudioData(arrayBuffer);
            const source = audioContext.createBufferSource();
            source.buffer = decodedBuffer;
            source.connect(audioContext.destination);
            source.start(0);

            source.onended = () => {
                addLog('system', 'ë‹µë³€ ì¬ìƒì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.');
                enableInputs(); // âœ¨ ì¬ìƒì´ 'ëë‚œ í›„'ì— ì…ë ¥ì°½/ë²„íŠ¼ í™œì„±í™”
            };
        } catch(e) {
            console.error(e);
            enableInputs(); // ì¬ìƒ ì˜¤ë¥˜ ì‹œì—ë„ í™œì„±í™”
        } finally {
            lastReceivedAudioBlob = null;
        }
    }
    
    // í˜ì´ì§€ ë¡œë“œ ì‹œ ì¦‰ì‹œ ì—°ê²°
    connectWebSocket();

</script>
</body>
</html>