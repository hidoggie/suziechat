# main.py (0722 ì˜¤í›„ 4ì‹œ 32ë¶„ ìµœì¢… ì™„ì„± ë° í†µí•© ë²„ì „)

import asyncio
import os
import re
import json
import time
import shutil
import base64
import io
from pathlib import Path
from contextlib import asynccontextmanager

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Body, HTTPException
from fastapi.responses import FileResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from PIL import Image
import fitz  # PyMuPDF

import google.generativeai as genai
from google.cloud import speech, texttospeech

# --- 1. ì„¤ì • ---
KNOWLEDGE_PDF_PATH = "knowledge.pdf"
IMAGES_DIR = Path(__file__).resolve().parent / "static" / "images"
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
MAX_OUTPUT_TOKENS = 1500
STT_CREDENTIALS_PATH = "/etc/secrets/voice-chat-462608-412b0459f610.json"
TTS_CREDENTIALS_PATH = "/etc/secrets/voice-chat-462608-e445e48514e2.json"
SAMPLE_RATE = 48000

# --- 2. ì „ì—­ ë³€ìˆ˜ ë° ì•± ì´ˆê¸°í™” ---
PDF_CONTENT = []
MODEL, STT_CLIENT, TTS_CLIENT = None, None, None
INITIALIZATION_ERROR = None

# --- 3. Lifespanì„ ì´ìš©í•œ ì•ˆì •ì ì¸ ì•± ì´ˆê¸°í™” ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    global MODEL, STT_CLIENT, TTS_CLIENT, PDF_CONTENT, INITIALIZATION_ERROR
    print("âœ¨ ì•± ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    try:
        # PDF ì²˜ë¦¬ ë¡œì§
        IMAGES_DIR.mkdir(parents=True, exist_ok=True)
        pdf_path = Path(__file__).resolve().parent / KNOWLEDGE_PDF_PATH
        if not pdf_path.exists(): raise FileNotFoundError(f"{pdf_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        doc = fitz.open(pdf_path)
        content_list = []
        for page_num, page in enumerate(doc):
            page_data = {"page": page_num, "text": page.get_text()}
            image_files = []
            for img_index, img in enumerate(page.get_images(full=True)):
                xref = img[0]
                base_image = doc.extract_image(xref)
                image_bytes = base_image["image"]
                try:
                    image_obj = Image.open(io.BytesIO(image_bytes))
                    image_filename = f"page_{page_num}_img_{img_index}.png"
                    image_obj.save(IMAGES_DIR / image_filename, "PNG")
                    image_files.append(image_filename)
                except Exception as img_e: print(f"ê²½ê³ : ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨ (í˜ì´ì§€ {page_num}): {img_e}")
            page_data["images"] = image_files
            content_list.append(page_data)
        PDF_CONTENT = content_list
        print(f"âœ… PDF ì²˜ë¦¬ ì™„ë£Œ: {len(doc)} í˜ì´ì§€, {sum(len(p['images']) for p in PDF_CONTENT)}ê°œ ì´ë¯¸ì§€ ì¶”ì¶œ")

        # API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        STT_CLIENT = speech.SpeechClient.from_service_account_file(STT_CREDENTIALS_PATH)
        TTS_CLIENT = texttospeech.TextToSpeechClient.from_service_account_file(TTS_CREDENTIALS_PATH)
        if not GEMINI_API_KEY: raise Exception("GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        genai.configure(api_key=GEMINI_API_KEY)
        
        system_instruction = f"""
            ë‹¹ì‹ ì€ ì „ë¬¸ Q&A ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
            ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´, ì œê³µë˜ëŠ” ì»¨í…ìŠ¤íŠ¸(í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€)ë§Œì„ ì‚¬ìš©í•˜ì—¬ ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. 
            ë§Œì•½ ë‹µë³€ì´ ì œê³µëœ íŠ¹ì • ì´ë¯¸ì§€ì™€ ê´€ë ¨ì´ ìˆë‹¤ë©´, ë°˜ë“œì‹œ ë‹µë³€ì˜ ë§¨ ëì— ë‹¤ìŒ í˜•ì‹ì˜ íƒœê·¸ë¥¼ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤: [IMAGE: ì´ë¯¸ì§€íŒŒì¼ì´ë¦„.png]
            
            âœ¨âœ¨âœ¨ [ì¤‘ìš” ê·œì¹™] âœ¨âœ¨âœ¨
                1. ëª¨ë“  ë‹µë³€ì€ ë°˜ë“œì‹œ 2000ì ì´ë‚´ë¡œ, í•µì‹¬ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì„œ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.
                2. ë‹µë³€ì´ ê¸¸ì–´ì§ˆ ê²½ìš°, ê°€ì¥ ì¤‘ìš”í•œ ì •ë³´ë¶€í„° ìˆœì„œëŒ€ë¡œ, ìµœëŒ€ 3~4ê°œì˜ ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
                
            """
        generation_config = genai.GenerationConfig(max_output_tokens=MAX_OUTPUT_TOKENS)
        MODEL = genai.GenerativeModel('gemini-1.5-flash', system_instruction=system_instruction, generation_config=generation_config)
        
        print("ğŸ‰ ëª¨ë“  ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ. ì±—ë´‡ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        INITIALIZATION_ERROR = f"[{type(e).__name__}] {e}"
        print(f"ğŸ’¥ FATAL: ì•± ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ! ì›ì¸: {INITIALIZATION_ERROR}")
    
    yield # ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
    
    print("ğŸ‘‹ ì„œë²„ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")

app = FastAPI(lifespan=lifespan)

# --- 4. FastAPI ì—”ë“œí¬ì¸íŠ¸ ---
BASE_DIR = Path(__file__).resolve().parent
app.mount("/static", StaticFiles(directory=BASE_DIR / "static"), name="static")

@app.get("/", response_class=FileResponse)
async def read_index(): return FileResponse(BASE_DIR / "static" / "index.html")

# âœ¨âœ¨âœ¨ /ar ê²½ë¡œ ì¶”ê°€ âœ¨âœ¨âœ¨
@app.get("/ar", response_class=FileResponse)
async def read_ar_page():
    return FileResponse(BASE_DIR / "static" / "ar.html")

@app.get("/api/pdf-content")
async def get_pdf_content():
    if INITIALIZATION_ERROR or not PDF_CONTENT:
        # ì´ˆê¸°í™” ì‹¤íŒ¨ ë˜ëŠ” ì»¨í…ì¸ ê°€ ì—†ëŠ” ê²½ìš° ëª…í™•í•œ ì˜¤ë¥˜ ë°˜í™˜
        return JSONResponse(
            status_code=500, 
            content={"error": "PDF content not loaded or initialization failed."}
        )
    
    # âœ¨ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ, ì›ë³¸ ë°°ì—´ êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •
    return JSONResponse(content=PDF_CONTENT)

@app.post("/api/tts")
async def text_to_speech_api(payload: dict = Body(...)):
    """ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±(MP3) ë°ì´í„°ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    text_to_speak = payload.get("text_to_speak")
    if not text_to_speak:
        raise HTTPException(status_code=400, detail="text_to_speak í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    if not TTS_CLIENT:
        print("ğŸ’¥ TTS API ì˜¤ë¥˜: TTS_CLIENTê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        raise HTTPException(status_code=500, detail="TTS client not initialized")
    
    try:
        print(f"ğŸ”Š AR TTS ìš”ì²­ ìˆ˜ì‹ : '{text_to_speak[:30]}...'")
        
        tts_request = texttospeech.SynthesizeSpeechRequest(
            input=texttospeech.SynthesisInput(text=text_to_speak),
            voice=texttospeech.VoiceSelectionParams(language_code="ko-KR", name="ko-KR-Wavenet-A"),
            audio_config=texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3),
        )
        
        tts_response = await asyncio.to_thread(TTS_CLIENT.synthesize_speech, request=tts_request)
        
        import base64
        audio_base64 = base64.b64encode(tts_response.audio_content).decode('utf-8')
        print("âœ… AR TTS ìŒì„± ìƒì„± ì„±ê³µ")
        return {"audio": audio_base64}
        
    except Exception as e:
        print(f"ğŸ’¥ TTS API ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: [{type(e).__name__}] {e}")
        raise HTTPException(status_code=500, detail=f"TTS API Error: {e}")
    

# âœ¨âœ¨âœ¨ AR ì´ë¯¸ì§€ ì¸ì‹ì„ ìœ„í•œ ìƒˆë¡œìš´ AI ì¿¼ë¦¬ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€ âœ¨âœ¨âœ¨
@app.post("/api/ar-query")
async def ar_query(image_name: str = Body(..., embed=True)):
    """
    ì¸ì‹ëœ ì´ë¯¸ì§€ ì´ë¦„ì„ ë°›ì•„, í•´ë‹¹ ì´ë¯¸ì§€ì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ
    Geminiê°€ ë™ì ìœ¼ë¡œ ìƒì„±í•œ ì„¤ëª…ê³¼ TTS ì˜¤ë””ì˜¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if MODEL is None:
        return {"error": "Model not initialized"}

    # PDF ì»¨í…ì¸ ì—ì„œ ì´ë¯¸ì§€ ì´ë¦„ìœ¼ë¡œ í•´ë‹¹ í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ ì°¾ê¸°
    context_text = ""
    for page in PDF_CONTENT:
        if image_name in page["images"]:
            context_text = page["text"]
            break
    
    if not context_text:
        return {"error": "Context not found for this image"}

    try:
        # Geminiì—ê²Œ ë™ì  ì„¤ëª…ì„ ìƒì„±í•˜ë„ë¡ ìš”ì²­í•˜ëŠ” í”„ë¡¬í”„íŠ¸
        prompt = f"""
        ë‹¹ì‹ ì€ ì „ë¬¸ ë°•ë¬¼ê´€ ë„ìŠ¨íŠ¸ì…ë‹ˆë‹¤.
        ì•„ë˜ëŠ” í•œ ì „ì‹œë¬¼ì— ëŒ€í•œ ê¸°ë³¸ ì •ë³´ì…ë‹ˆë‹¤. ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì‹¤ì œ ê´€ëŒê°ì—ê²Œ ì„¤ëª…í•˜ë“¯ì´ ìƒìƒí•˜ê³  í¥ë¯¸ë¡œìš´ í•´ì„¤ì„ 1~2 ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ìƒì„±í•´ì£¼ì„¸ìš”.

        --- ê¸°ë³¸ ì •ë³´ ---
        {context_text}
        """
        
        gemini_response = await MODEL.generate_content_async(prompt)
        ai_text = gemini_response.text.strip()

        # ìƒì„±ëœ ì„¤ëª…ìœ¼ë¡œ TTS ì˜¤ë””ì˜¤ ìƒì„±
        tts_request = texttospeech.SynthesizeSpeechRequest(
            input=texttospeech.SynthesisInput(text=ai_text),
            voice=texttospeech.VoiceSelectionParams(language_code="ko-KR", name="ko-KR-Wavenet-A"),
            audio_config=texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3),
        )
        tts_response = await asyncio.to_thread(TTS_CLIENT.synthesize_speech, request=tts_request)
        
        import base64
        audio_base64 = base64.b64encode(tts_response.audio_content).decode('utf-8')

        return {
            "text": ai_text,
            "audio": audio_base64
        }

    except Exception as e:
        print(f"ğŸ’¥ AR ì¿¼ë¦¬ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return {"error": str(e)}    

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    
    if INITIALIZATION_ERROR:
        await websocket.send_json({"type": "error", "data": f"ì„œë²„ ì´ˆê¸°í™” ì‹¤íŒ¨: {INITIALIZATION_ERROR}"})
        await websocket.close(); return
            
    client_id = f"{websocket.client.host}:{websocket.client.port}"
    print(f"âœ… í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ë¨: {client_id}")
    try:
        while True:
            raw_data = await websocket.receive_json()
            message_type = raw_data.get("type"); user_input = raw_data.get("data")
            user_text = ""

            if message_type == "audio":
                audio_bytes = base64.b64decode(user_input)
                stt_request = speech.RecognizeRequest(config=speech.RecognitionConfig(encoding=speech.RecognitionConfig.AudioEncoding.WEBM_OPUS, sample_rate_hertz=SAMPLE_RATE, language_code="ko-KR"), audio=speech.RecognitionAudio(content=audio_bytes))
                stt_response = await asyncio.to_thread(STT_CLIENT.recognize, request=stt_request)
                user_text = stt_response.results[0].alternatives[0].transcript if stt_response.results else ""
                if user_text: await websocket.send_json({"type": "user_text", "data": user_text})
            
            elif message_type == "text":
                user_text = user_input

            if user_text:
                if "ì´ì œ ê·¸ë§Œ" in user_text.strip():
                    ai_text = "ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ì´ìš©í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤."
                    await websocket.send_json({"type": "ai_text", "data": ai_text})
                    # ... (TTS ë° ì¢…ë£Œ ë¡œì§)
                    break
                
                keywords = user_text.split()
                relevant_pages = [p for p in PDF_CONTENT if any(kw.lower() in p["text"].lower() for kw in keywords if len(kw) > 1)] or PDF_CONTENT
                
                prompt_parts = [ "ì•„ë˜ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•´ì¤˜. ì´ë¯¸ì§€ì— ëŒ€í•´ ì–¸ê¸‰í•  ë•ŒëŠ”, ë‚´ê°€ ì•Œë ¤ì¤€ 'ì´ë¯¸ì§€ íŒŒì¼ëª…'ì„ ì‚¬ìš©í•˜ì—¬ `[IMAGE: íŒŒì¼ëª…]` íƒœê·¸ë¥¼ ë‹µë³€ ë§¨ ëì— ë¶™ì—¬ì•¼ í•´. ë‹µë³€ ë³¸ë¬¸ì—ëŠ” íŒŒì¼ëª…ì„ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆ." ]
                for page in relevant_pages[:3]:
                    prompt_parts.append(f"\n--- ì°¸ê³  í…ìŠ¤íŠ¸ (í˜ì´ì§€ {page['page']+1}) ---\n{page['text']}")
                    if page["images"]:
                        for img_file in page["images"]:
                            img_path = IMAGES_DIR / img_file
                            if img_path.exists():
                                try:
                                    prompt_parts.append(f"ì°¸ê³  ì´ë¯¸ì§€ íŒŒì¼ëª…: {img_file}")
                                    prompt_parts.append(Image.open(img_path))
                                except Exception as img_e: print(f"ê²½ê³ : ì´ë¯¸ì§€ ì—´ê¸° ì‹¤íŒ¨ {img_path}: {img_e}")
                
                prompt_parts.append(f"\n--- ì§ˆë¬¸ ---\n{user_text}")

                gemini_response = await MODEL.generate_content_async(prompt_parts)
                ai_text_raw = gemini_response.text
                
                image_tag_match = re.search(r"\[IMAGE:\s*(page_\d+_img_\d+\.\w+)\]", ai_text_raw)
                ai_text = re.sub(r"\[IMAGE:\s*(.*?)\]", "", ai_text_raw).strip()
                await websocket.send_json({"type": "ai_text", "data": ai_text})

                if image_tag_match:
                    image_filename = image_tag_match.group(1).strip()
                    image_url = f"/static/images/{image_filename}"
                    await websocket.send_json({"type": "ai_image", "url": image_url})

                tts_request = texttospeech.SynthesizeSpeechRequest(input=texttospeech.SynthesisInput(text=ai_text), voice=texttospeech.VoiceSelectionParams(language_code="ko-KR", name="ko-KR-Wavenet-A"), audio_config=texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3))
                tts_response = await asyncio.to_thread(TTS_CLIENT.synthesize_speech, request=tts_request)
                if tts_response.audio_content: await websocket.send_bytes(tts_response.audio_content)

    except WebSocketDisconnect: print(f"ğŸ”Œ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ëŠì–´ì§: {client_id}")
    except Exception as e: print(f"ğŸ’¥ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ({client_id}): {e}")
    finally: print(f"ğŸ ì›¹ì†Œì¼“ ì„¸ì…˜ ì¢…ë£Œ: {client_id}")