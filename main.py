# main.py (0721 ì˜¤í›„ 10ì‹œ 09ë¶„ ìµœì¢… ì™„ì„± ë° í†µí•© ë²„ì „)

import asyncio
import os
import re
import json
import time
import shutil
import base64
import io
from pathlib import Path

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Body
from fastapi.responses import FileResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from PIL import Image
import fitz  # PyMuPDF

import google.generativeai as genai
from google.cloud import speech, texttospeech

# --- 1. ì„¤ì • ---
KNOWLEDGE_PDF_PATH = "knowledge.pdf"
IMAGES_DIR = Path(__file__).resolve().parent / "static" / "images"
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
MAX_OUTPUT_TOKENS = 1500
STT_CREDENTIALS_PATH = "/etc/secrets/voice-chat-462608-412b0459f610.json"
TTS_CREDENTIALS_PATH = "/etc/secrets/voice-chat-462608-e445e48514e2.json"
SAMPLE_RATE = 48000

# --- 2. ì „ì—­ ë³€ìˆ˜ ë° ì•± ì´ˆê¸°í™” ---
app = FastAPI()
PDF_CONTENT, MODEL, STT_CLIENT, TTS_CLIENT = [], None, None, None
app_lock = asyncio.Lock()
INITIALIZATION_ERROR = None

# --- 3. ì²« ì ‘ì† ì‹œ ë¦¬ì†ŒìŠ¤ë¥¼ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜ ---
async def initialize_app():
    global PDF_CONTENT, MODEL, STT_CLIENT, TTS_CLIENT, INITIALIZATION_ERROR
    async with app_lock:
        if MODEL is not None or INITIALIZATION_ERROR is not None: return

        print("âœ¨ ì•± ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        try:
            # 1. ê¸°ì¡´ ì´ë¯¸ì§€ í´ë” ì‚­ì œ ë° ì¬ìƒì„±
            if IMAGES_DIR.exists(): shutil.rmtree(IMAGES_DIR)
            IMAGES_DIR.mkdir(parents=True, exist_ok=True)

            # 2. PDF ì²˜ë¦¬
            pdf_path = Path(__file__).resolve().parent / KNOWLEDGE_PDF_PATH
            if not pdf_path.exists(): raise FileNotFoundError(f"{pdf_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            doc = fitz.open(pdf_path)
            for page_num, page in enumerate(doc):
                page_data = {"page": page_num, "text": page.get_text()}
                image_files = []
                for img_index, img in enumerate(page.get_images(full=True)):
                    xref = img[0]
                    base_image = doc.extract_image(xref)
                    image_bytes = base_image["image"]
                    try:
                        image_obj = Image.open(io.BytesIO(image_bytes))
                        image_filename = f"page_{page_num}_img_{img_index}.png"
                        image_obj.save(IMAGES_DIR / image_filename, "PNG")
                        image_files.append(image_filename)
                    except Exception as img_e: print(f"ê²½ê³ : ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨ (í˜ì´ì§€ {page_num}): {img_e}")
                page_data["images"] = image_files
                PDF_CONTENT.append(page_data)
            print(f"âœ… PDF ì²˜ë¦¬ ì™„ë£Œ: {len(doc)} í˜ì´ì§€, {sum(len(p['images']) for p in PDF_CONTENT)}ê°œ ì´ë¯¸ì§€ ì¶”ì¶œ")

            # 3. í´ë¼ì´ì–¸íŠ¸ ë° ëª¨ë¸ ì´ˆê¸°í™”
            STT_CLIENT = speech.SpeechClient.from_service_account_file(STT_CREDENTIALS_PATH)
            TTS_CLIENT = texttospeech.TextToSpeechClient.from_service_account_file(TTS_CREDENTIALS_PATH)
            
            if not GEMINI_API_KEY: raise Exception("GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            genai.configure(api_key=GEMINI_API_KEY)
            
            system_instruction = f"""
                ë‹¹ì‹ ì€ ì „ë¬¸ Q&A ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
                ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´, ì œê³µë˜ëŠ” ì»¨í…ìŠ¤íŠ¸(í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€)ë§Œì„ ì‚¬ìš©í•˜ì—¬ ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. 
                ë‹µë³€ ë³¸ë¬¸ì—ëŠ” ì´ë¯¸ì§€ íŒŒì¼ëª…ì„ ì ˆëŒ€ ì§ì ‘ ì–¸ê¸‰í•˜ì§€ ë§ê³ , ì´ë¯¸ì§€ë¥¼ ì°¸ê³ í–ˆì„ ê²½ìš°ì—ë§Œ ë‹µë³€ ë§ˆì§€ë§‰ì— `[IMAGE: ì´ë¯¸ì§€íŒŒì¼ì´ë¦„.png]` íƒœê·¸ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.
                ë‹¹ì‹ ì˜ ë‚´ë¶€ ì§€ì‹ì´ë‚˜ ë‹¤ë¥¸ ì •ë³´ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.

                âœ¨âœ¨âœ¨ [ì¤‘ìš” ê·œì¹™] âœ¨âœ¨âœ¨
                1. ëª¨ë“  ë‹µë³€ì€ ë°˜ë“œì‹œ 2000ì ì´ë‚´ë¡œ, í•µì‹¬ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì„œ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.
                2. ë‹µë³€ì´ ê¸¸ì–´ì§ˆ ê²½ìš°, ê°€ì¥ ì¤‘ìš”í•œ ì •ë³´ë¶€í„° ìˆœì„œëŒ€ë¡œ, ìµœëŒ€ 3~4ê°œì˜ ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
                3. ì¹œì ˆí•˜ê³  ëª…í™•í•œ í•œêµ­ì–´ ë§íˆ¬ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.

            """
            generation_config = genai.GenerationConfig(max_output_tokens=MAX_OUTPUT_TOKENS)
            MODEL = genai.GenerativeModel('gemini-1.5-pro-flash', system_instruction=system_instruction, generation_config=generation_config)
            
            print("ğŸ‰ ëª¨ë“  ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ. ì±—ë´‡ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            INITIALIZATION_ERROR = f"[{type(e).__name__}] {e}"
            print(f"ğŸ’¥ FATAL: ì•± ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ! ì›ì¸: {INITIALIZATION_ERROR}")

# --- 4. FastAPI ì—”ë“œí¬ì¸íŠ¸ ---
BASE_DIR = Path(__file__).resolve().parent
app.mount("/static", StaticFiles(directory=BASE_DIR / "static"), name="static")

@app.get("/", response_class=FileResponse)
async def read_index(): return FileResponse(BASE_DIR / "static" / "index.html")

# âœ¨âœ¨âœ¨ /ar ê²½ë¡œ ì¶”ê°€ âœ¨âœ¨âœ¨
@app.get("/ar", response_class=FileResponse)
async def read_ar_page():
    return FileResponse(BASE_DIR / "static" / "ar.html")

@app.get("/api/pdf-content")
async def get_pdf_content():
    if not PDF_CONTENT: return {"error": "PDF content not loaded"}
    return PDF_CONTENT

@app.post("/api/tts")
async def text_to_speech_api(text_to_speak: str = Body(..., embed=True)):
    if not TTS_CLIENT: return {"error": "TTS client not initialized"}
    try:
        tts_request = texttospeech.SynthesizeSpeechRequest(
            input=texttospeech.SynthesisInput(text=text_to_speak),
            voice=texttospeech.VoiceSelectionParams(language_code="ko-KR", name="ko-KR-Wavenet-A"),
            audio_config=texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3),
        )
        tts_response = await asyncio.to_thread(TTS_CLIENT.synthesize_speech, request=tts_request)
        audio_base64 = base64.b64encode(tts_response.audio_content).decode('utf-8')
        return {"audio": audio_base64}
    except Exception as e:
        print(f"ğŸ’¥ TTS API ì—”ë“œí¬ì¸íŠ¸ ì˜¤ë¥˜: {e}"); return {"error": str(e)}

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    if MODEL is None: await initialize_app()
    if INITIALIZATION_ERROR:
        await websocket.send_json({"type": "error", "data": f"ì„œë²„ ì´ˆê¸°í™” ì‹¤íŒ¨: {INITIALIZATION_ERROR}"})
        await websocket.close(); return
            
    client_id = f"{websocket.client.host}:{websocket.client.port}"
    print(f"âœ… í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ë¨: {client_id}")
    try:
        while True:
            raw_data = await websocket.receive_json()
            message_type = raw_data.get("type"); user_input = raw_data.get("data")
            user_text = ""

            if message_type == "audio":
                audio_bytes = base64.b64decode(user_input)
                stt_request = speech.RecognizeRequest(config=speech.RecognitionConfig(encoding=speech.RecognitionConfig.AudioEncoding.WEBM_OPUS, sample_rate_hertz=SAMPLE_RATE, language_code="ko-KR"), audio=speech.RecognitionAudio(content=audio_bytes))
                stt_response = await asyncio.to_thread(STT_CLIENT.recognize, request=stt_request)
                user_text = stt_response.results[0].alternatives[0].transcript if stt_response.results else ""
                if user_text: await websocket.send_json({"type": "user_text", "data": user_text})
            
            elif message_type == "text":
                user_text = user_input

            if user_text:
                if "ì´ì œ ê·¸ë§Œ" in user_text.strip():
                    ai_text = "ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ì´ìš©í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤."
                    await websocket.send_json({"type": "ai_text", "data": ai_text})
                    # ... (TTS ë° ì¢…ë£Œ ë¡œì§)
                    break
                
                keywords = user_text.split()
                relevant_pages = [p for p in PDF_CONTENT if any(kw.lower() in p["text"].lower() for kw in keywords if len(kw) > 1)] or PDF_CONTENT
                
                prompt_parts = [ "ì•„ë˜ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•´ì¤˜. ì´ë¯¸ì§€ì— ëŒ€í•´ ì–¸ê¸‰í•  ë•ŒëŠ”, ë‚´ê°€ ì•Œë ¤ì¤€ 'ì´ë¯¸ì§€ íŒŒì¼ëª…'ì„ ì‚¬ìš©í•˜ì—¬ `[IMAGE: íŒŒì¼ëª…]` íƒœê·¸ë¥¼ ë‹µë³€ ë§¨ ëì— ë¶™ì—¬ì•¼ í•´. ë‹µë³€ ë³¸ë¬¸ì—ëŠ” íŒŒì¼ëª…ì„ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆ." ]
                for page in relevant_pages[:3]:
                    prompt_parts.append(f"\n--- ì°¸ê³  í…ìŠ¤íŠ¸ (í˜ì´ì§€ {page['page']+1}) ---\n{page['text']}")
                    if page["images"]:
                        for img_file in page["images"]:
                            img_path = IMAGES_DIR / img_file
                            if img_path.exists():
                                try:
                                    prompt_parts.append(f"ì°¸ê³  ì´ë¯¸ì§€ íŒŒì¼ëª…: {img_file}")
                                    prompt_parts.append(Image.open(img_path))
                                except Exception as img_e: print(f"ê²½ê³ : ì´ë¯¸ì§€ ì—´ê¸° ì‹¤íŒ¨ {img_path}: {img_e}")
                
                prompt_parts.append(f"\n--- ì§ˆë¬¸ ---\n{user_text}")

                gemini_response = await MODEL.generate_content_async(prompt_parts)
                ai_text_raw = gemini_response.text
                
                image_tag_match = re.search(r"\[IMAGE:\s*(page_\d+_img_\d+\.\w+)\]", ai_text_raw)
                ai_text = re.sub(r"\[IMAGE:\s*(.*?)\]", "", ai_text_raw).strip()
                await websocket.send_json({"type": "ai_text", "data": ai_text})

                if image_tag_match:
                    image_filename = image_tag_match.group(1).strip()
                    image_url = f"/static/images/{image_filename}"
                    await websocket.send_json({"type": "ai_image", "url": image_url})

                tts_request = texttospeech.SynthesizeSpeechRequest(input=texttospeech.SynthesisInput(text=ai_text), voice=texttospeech.VoiceSelectionParams(language_code="ko-KR", name="ko-KR-Wavenet-A"), audio_config=texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3))
                tts_response = await asyncio.to_thread(TTS_CLIENT.synthesize_speech, request=tts_request)
                if tts_response.audio_content: await websocket.send_bytes(tts_response.audio_content)

    except WebSocketDisconnect: print(f"ğŸ”Œ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ëŠì–´ì§: {client_id}")
    except Exception as e: print(f"ğŸ’¥ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ({client_id}): {e}")
    finally: print(f"ğŸ ì›¹ì†Œì¼“ ì„¸ì…˜ ì¢…ë£Œ: {client_id}")