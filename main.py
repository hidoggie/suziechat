# main.py (ìµœì¢… ì™„ì„±ë³¸)

import asyncio
import io
import os
from pathlib import Path
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import FileResponse
from fastapi.staticfiles import StaticFiles

import google.generativeai as genai
from google.cloud import speech, texttospeech

# --- 1. ì„¤ì • ---
KNOWLEDGE_FILE_PATH = "knowledge.txt" # ì‚¬ìš©í•  ì§€ì‹ íŒŒì¼ ì´ë¦„
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
MAX_OUTPUT_TOKENS = 1500
STT_CREDENTIALS_PATH = "/etc/secrets/voice-chat-462608-412b0459f610.json"
TTS_CREDENTIALS_PATH = "/etc/secrets/voice-chat-462608-e445e48514e2.json"
SAMPLE_RATE = 16000 # ë¸Œë¼ìš°ì € MediaRecorderì˜ ê¸°ë³¸ ìƒ˜í”Œë§ ë ˆì´íŠ¸ì™€ ì¼ì¹˜

# --- 2. ì „ì—­ ë³€ìˆ˜ ë° ìƒíƒœ ê´€ë¦¬ ---
app = FastAPI()
KNOWLEDGE_CONTEXT, MODEL, STT_CLIENT, TTS_CLIENT = None, None, None, None
app_lock = asyncio.Lock()
APP_INITIALIZATION_FAILED = False
# âœ¨âœ¨âœ¨ ì‹¤íŒ¨ ì‹œì˜ ìƒì„¸ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ì €ì¥í•  ì „ì—­ ë³€ìˆ˜ ì¶”ê°€ âœ¨âœ¨âœ¨
INITIALIZATION_ERROR_MESSAGE = "ì•Œ ìˆ˜ ì—†ëŠ” ì´ˆê¸°í™” ì˜¤ë¥˜"


# --- 3. í—¬í¼ í•¨ìˆ˜ ---
async def initialize_app():
    global KNOWLEDGE_CONTEXT, MODEL, STT_CLIENT, TTS_CLIENT, APP_INITIALIZATION_FAILED, INITIALIZATION_ERROR_MESSAGE
    
    async with app_lock:
        if KNOWLEDGE_CONTEXT is not None or APP_INITIALIZATION_FAILED: return

        print("âœ¨ ì²« ì‚¬ìš©ì ì ‘ì†. ì•± ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        try:
            # ê° ë‹¨ê³„ë³„ë¡œ ëª…í™•í•˜ê²Œ ì‹¤í–‰
    # 1. ë¡œì»¬ íŒŒì¼ì—ì„œ ì§€ì‹ ì»¨í…ìŠ¤íŠ¸ ë¡œë”©
            print(f"ğŸ“„ '{KNOWLEDGE_FILE_PATH}' íŒŒì¼ì—ì„œ ì •ë³´ ë¡œë”© ì¤‘...")
            file_path = BASE_DIR / KNOWLEDGE_FILE_PATH
            if not file_path.exists(): raise FileNotFoundError(f"{file_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            with open(file_path, "r", encoding="utf-8") as f:
                KNOWLEDGE_CONTEXT = f.read()
            print("âœ… íŒŒì¼ ë¡œë”© ì„±ê³µ!")

            print("2/4: STT í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”...")
            STT_CLIENT = speech.SpeechClient.from_service_account_file(STT_CREDENTIALS_PATH)
            print("âœ… STT í´ë¼ì´ì–¸íŠ¸ ì„±ê³µ")

            print("3/4: TTS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”...")
            TTS_CLIENT = texttospeech.TextToSpeechClient.from_service_account_file(TTS_CREDENTIALS_PATH)
            print("âœ… TTS í´ë¼ì´ì–¸íŠ¸ ì„±ê³µ")
            
            print("4/4: Gemini ëª¨ë¸ ì´ˆê¸°í™”...")
            if not GEMINI_API_KEY: raise Exception("GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            genai.configure(api_key=GEMINI_API_KEY)
            
            system_instruction = f"""
            ë‹¹ì‹ ì€ ë‹¤ìŒ 'ì œê³µëœ ë‚´ìš©'ì— ëŒ€í•´ì„œë§Œ ë‹µë³€í•˜ëŠ” ì „ë¬¸ Q&A ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
            [ì¤‘ìš” ê·œì¹™]
            1. ëª¨ë“  ë‹µë³€ì€ ê°„ê²°í•˜ê²Œ, í•µì‹¬ë§Œ ìš”ì•½í•´ì„œ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.
            2. 'ì œê³µëœ ë‚´ìš©'ì— ì •ë³´ê°€ ì—†ìœ¼ë©´, "ì œê°€ ê°€ì§„ ì •ë³´ ë‚´ì—ì„œëŠ” ë‹µë³€í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤."ë¼ê³  ì†”ì§í•˜ê²Œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
            --- ì œê³µëœ ë‚´ìš© ---
            {KNOWLEDGE_CONTEXT}
            """
            generation_config = genai.GenerationConfig(max_output_tokens=MAX_OUTPUT_TOKENS)
            MODEL = genai.GenerativeModel('gemini-1.5-flash', system_instruction=system_instruction, generation_config=generation_config)

            print("ğŸ‰ ëª¨ë“  ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ. ì±—ë´‡ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            # âœ¨ ì˜¤ë¥˜ ë°œìƒ ì‹œ, ì‹¤íŒ¨ í”Œë˜ê·¸ì™€ í•¨ê»˜ ìƒì„¸ ë©”ì‹œì§€ë¥¼ ì „ì—­ ë³€ìˆ˜ì— ì €ì¥
            APP_INITIALIZATION_FAILED = True
            error_type = type(e).__name__
            INITIALIZATION_ERROR_MESSAGE = f"[{error_type}] {e}"
            print("="*60)
            print(f"ğŸ’¥ FATAL: ì•± ì´ˆê¸°í™” ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ! ğŸ’¥")
            print(f"ìƒì„¸ ì›ì¸: {INITIALIZATION_ERROR_MESSAGE}")
            print("="*60)


# --- 4. FastAPI ì—”ë“œí¬ì¸íŠ¸ ---
BASE_DIR = Path(__file__).resolve().parent
app.mount("/static", StaticFiles(directory=BASE_DIR / "static"), name="static")

@app.get("/", response_class=FileResponse)
async def read_index():
    return FileResponse(BASE_DIR / "static" / "index.html")

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    
    if MODEL is None:
        await initialize_app()
    
    # ì´ˆê¸°í™” ìµœì¢… ì‹¤íŒ¨ ì‹œ, ìƒì„¸ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì „ì†¡
    if APP_INITIALIZATION_FAILED:
        error_msg = f"ì„œë²„ ì´ˆê¸°í™” ì‹¤íŒ¨: {INITIALIZATION_ERROR_MESSAGE}"
        await websocket.send_json({"type": "ai_text", "data": error_msg})
        await websocket.close()
        return
            
    client_id = f"{websocket.client.host}:{websocket.client.port}"
    print(f"âœ… í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ë¨: {client_id}")

    try:
        while True:
            try:
                audio_bytes = await websocket.receive_bytes()
                config = speech.RecognitionConfig(
                    encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
                    sample_rate_hertz=SAMPLE_RATE, # ë¸Œë¼ìš°ì €ì˜ MediaRecorderê°€ ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” ìƒ˜í”Œë§ ë ˆì´íŠ¸
                    language_code="ko-KR"
                )
                audio = speech.RecognitionAudio(content=audio_bytes)
                stt_response = STT_CLIENT.recognize(config=config, audio=audio)
                user_text = stt_response.results[0].alternatives[0].transcript if stt_response.results else ""

                if user_text:
                    await websocket.send_json({"type": "user_text", "data": user_text})
                    if "ì´ì œ ê·¸ë§Œ" in user_text.strip():
                        ai_text = "ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ì´ìš©í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤."
                    else:
                        gemini_response = await MODEL.generate_content_async(user_text)
                        ai_text = gemini_response.text
                    
                    await websocket.send_json({"type": "ai_text", "data": ai_text})
                    
                    input_text = texttospeech.SynthesisInput(text=ai_text)
                    voice = texttospeech.VoiceSelectionParams(language_code="ko-KR", name="ko-KR-Wavenet-A")
                    audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)
                    tts_response = TTS_CLIENT.synthesize_speech(input=input_text, voice=voice, audio_config=audio_config)
                    if tts_response.audio_content:
                        await websocket.send_bytes(tts_response.audio_content)
                    
                    if "ì´ì œ ê·¸ë§Œ" in user_text.strip():
                        await asyncio.sleep(1); break
            except WebSocketDisconnect:
                print(f"ğŸ”Œ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ëŠì–´ì§: {client_id}"); break
            except Exception as e:
                print(f"ğŸ’¥ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ({client_id}): {e}")
                await websocket.send_json({"type": "ai_text", "data": "ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."})
    except Exception as e:
        print(f"ğŸ’¥ ì›¹ì†Œì¼“ì˜ ìµœìƒìœ„ ì˜¤ë¥˜: {e}")
    finally:
        print(f"ğŸ ì›¹ì†Œì¼“ ì„¸ì…˜ ì¢…ë£Œ: {client_id}")