# main.py (0722 ì˜¤í›„ 4ì‹œ 32ë¶„ ìµœì¢… ì™„ì„± ë° í†µí•© ë²„ì „)

import asyncio
import os
import re
import json
#--- import time ---
import shutil
import base64
import io
from pathlib import Path
from contextlib import asynccontextmanager

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Body, HTTPException
from fastapi.responses import FileResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from PIL import Image
import fitz  # PyMuPDF

import google.generativeai as genai
from google.cloud import speech, texttospeech

import numpy as np # ë²¡í„° ê³„ì‚°ì„ ìœ„í•´ ì¶”ê°€


# --- 1. ì„¤ì • ---
KNOWLEDGE_PDF_PATH = "knowledge.pdf"
IMAGES_DIR = Path(__file__).resolve().parent / "static" / "images"
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
MAX_OUTPUT_TOKENS = 1500
STT_CREDENTIALS_PATH = "/etc/secrets/voice-chat-462608-412b0459f610.json"
TTS_CREDENTIALS_PATH = "/etc/secrets/voice-chat-462608-e445e48514e2.json"
SAMPLE_RATE = 48000

# --- 2. ì „ì—­ ë³€ìˆ˜ ë° ì•± ì´ˆê¸°í™” ---
PDF_CONTENT = []
MODEL, STT_CLIENT, TTS_CLIENT = None, None, None
INITIALIZATION_ERROR = None

EMBEDDING_MODEL = "models/text-embedding-004"

# --- 3. Lifespanì„ ì´ìš©í•œ ì•ˆì •ì ì¸ ì•± ì´ˆê¸°í™” ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    global MODEL, STT_CLIENT, TTS_CLIENT, PDF_CONTENT, INITIALIZATION_ERROR,  EMBEDDING_MODEL
    print("âœ¨ ì•± ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

    try:
      #  if IMAGES_DIR.exists(): shutil.rmtree(IMAGES_DIR)
        # PDF ì²˜ë¦¬ ë¡œì§
        IMAGES_DIR.mkdir(parents=True, exist_ok=True)
        print(f"âœ… ì´ë¯¸ì§€ ì €ì¥ í´ë” í™•ì¸/ìƒì„± ì™„ë£Œ: {IMAGES_DIR}")

        pdf_path = Path(__file__).resolve().parent / KNOWLEDGE_PDF_PATH
        if not pdf_path.exists(): raise FileNotFoundError(f"{pdf_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        doc = fitz.open(pdf_path)
        content_list = []

        for page_num in range(len(doc)):
            page = doc.load_page(page_num) # í˜ì´ì§€ë¥¼ ë²ˆí˜¸ë¡œ ëª…ì‹œí•˜ì—¬ ë¡œë“œ
            
            page_text = page.get_text("text")
            page_images = page.get_images(full=True)

            page_data = {"page": page_num, "text": page_text, "images": []}
           
            
            for img_index, img in enumerate(page_images):
                xref = img[0]
                base_image = doc.extract_image(xref)
                image_bytes = base_image["image"]
                try:
                    image_obj = Image.open(io.BytesIO(image_bytes))
                    image_filename = f"page_{page_num}_img_{img_index}.png"
                    image_obj.save(IMAGES_DIR / image_filename, "PNG")
                    page_data["images"].append(image_filename)
                except Exception as img_e:
                    print(f"ê²½ê³ : ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨ (í˜ì´ì§€ {page_num}): {img_e}")

            content_list.append(page_data)

        PDF_CONTENT = content_list
        print(f"âœ… PDF ì²˜ë¦¬ ì™„ë£Œ: {len(doc)} í˜ì´ì§€, {sum(len(p['images']) for p in PDF_CONTENT)}ê°œ ì´ë¯¸ì§€ ì¶”ì¶œ")

        # âœ¨âœ¨âœ¨ ë””ë²„ê¹…ì„ ìœ„í•œ íŒŒì¼ ì €ì¥ ì½”ë“œ ì¶”ê°€ âœ¨âœ¨âœ¨
        try:
            debug_path = Path(__file__).resolve().parent / "debug_content.json"
            with open(debug_path, "w", encoding="utf-8") as f:
                json.dump(PDF_CONTENT, f, ensure_ascii=False, indent=2)
            print(f"âœ… ë””ë²„ê¹… íŒŒì¼ ì €ì¥ ì™„ë£Œ: {debug_path}")
        except Exception as e:
            print(f"ğŸ’¥ ë””ë²„ê¹… íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")


        # âœ¨âœ¨âœ¨ PDF í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì„ë² ë”© ë²¡í„° ìƒì„± (í•µì‹¬ ì¶”ê°€) âœ¨âœ¨âœ¨
        print("ğŸ¤– PDF ì»¨í…ì¸ ì— ëŒ€í•œ ì„ë² ë”© ë²¡í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
        texts_to_embed = [page['text'] for page in PDF_CONTENT]
        # ë°°ì¹˜(batch)ë¡œ ì²˜ë¦¬í•˜ì—¬ íš¨ìœ¨ì„± ì¦ëŒ€
        embedding_response = genai.embed_content(model=EMBEDDING_MODEL, content=texts_to_embed, task_type="RETRIEVAL_DOCUMENT")
        
        # ê° í˜ì´ì§€ ë°ì´í„°ì— ì„ë² ë”© ê²°ê³¼ ì¶”ê°€
        for i, page_data in enumerate(PDF_CONTENT):
            page_data['embedding'] = embedding_response['embedding'][i]
        print(f"âœ… {len(PDF_CONTENT)}ê°œ í˜ì´ì§€ì— ëŒ€í•œ ì„ë² ë”© ìƒì„± ì™„ë£Œ.")


        # API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        STT_CLIENT = speech.SpeechClient.from_service_account_file(STT_CREDENTIALS_PATH)
        TTS_CLIENT = texttospeech.TextToSpeechClient.from_service_account_file(TTS_CREDENTIALS_PATH)
        if not GEMINI_API_KEY: raise Exception("GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        genai.configure(api_key=GEMINI_API_KEY)
        
        system_instruction = f"""
            ë‹¹ì‹ ì€ ì „ë¬¸ Q&A ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
            ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´, ì œê³µë˜ëŠ” ì»¨í…ìŠ¤íŠ¸(í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€)ë§Œì„ ì‚¬ìš©í•˜ì—¬ ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. 
            ë§Œì•½ ë‹µë³€ì´ ì œê³µëœ íŠ¹ì • ì´ë¯¸ì§€ì™€ ê´€ë ¨ì´ ìˆë‹¤ë©´, ë°˜ë“œì‹œ ë‹µë³€ì˜ ë§¨ ëì— ë‹¤ìŒ í˜•ì‹ì˜ íƒœê·¸ë¥¼ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤: [IMAGE: ì´ë¯¸ì§€íŒŒì¼ì´ë¦„.png]
            
            âœ¨âœ¨âœ¨ [ì¤‘ìš” ê·œì¹™] âœ¨âœ¨âœ¨
                1. ëª¨ë“  ë‹µë³€ì€ ë°˜ë“œì‹œ 2000ì ì´ë‚´ë¡œ, í•µì‹¬ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì„œ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.
                2. ë‹µë³€ì´ ê¸¸ì–´ì§ˆ ê²½ìš°, ê°€ì¥ ì¤‘ìš”í•œ ì •ë³´ë¶€í„° ìˆœì„œëŒ€ë¡œ, ìµœëŒ€ 3~4ê°œì˜ ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
                
            """
        generation_config = genai.GenerationConfig(max_output_tokens=MAX_OUTPUT_TOKENS)
        MODEL = genai.GenerativeModel('gemini-1.5-flash', system_instruction=system_instruction, generation_config=generation_config)
        
        print("ğŸ‰ ëª¨ë“  ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ. ì±—ë´‡ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        INITIALIZATION_ERROR = f"[{type(e).__name__}] {e}"
        print(f"ğŸ’¥ FATAL: ì•± ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ! ì›ì¸: {INITIALIZATION_ERROR}")

    yield # ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
    
    print("ğŸ‘‹ ì„œë²„ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")

app = FastAPI(lifespan=lifespan)

# --- 4. FastAPI ì—”ë“œí¬ì¸íŠ¸ ---
BASE_DIR = Path(__file__).resolve().parent
app.mount("/static", StaticFiles(directory=BASE_DIR / "static"), name="static")

@app.get("/", response_class=FileResponse)
async def read_index(): return FileResponse(BASE_DIR / "static" / "index.html")

# âœ¨âœ¨âœ¨ /ar ê²½ë¡œ ì¶”ê°€ âœ¨âœ¨âœ¨
@app.get("/ar", response_class=FileResponse)
async def read_ar_page():
    return FileResponse(BASE_DIR / "static" / "ar.html")

@app.get("/api/pdf-content")
async def get_pdf_content():
    if INITIALIZATION_ERROR or not PDF_CONTENT:
        # ì´ˆê¸°í™” ì‹¤íŒ¨ ë˜ëŠ” ì»¨í…ì¸ ê°€ ì—†ëŠ” ê²½ìš° ëª…í™•í•œ ì˜¤ë¥˜ ë°˜í™˜
        return JSONResponse(
            status_code=500, 
            content={"error": "PDF content not loaded or initialization failed."}
        )
    
    # âœ¨ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ, ì›ë³¸ ë°°ì—´ êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •
    return JSONResponse(content=PDF_CONTENT)

@app.post("/api/tts")
async def text_to_speech_api(payload: dict = Body(...)):
    # âœ¨ 1. ìŒì„± ì•ˆë‚´ ë²„íŠ¼ ì˜¤ë¥˜ ìˆ˜ì •ì„ ìœ„í•œ ìµœì¢… TTS API ì½”ë“œ
    text_to_speak = payload.get("text_to_speak")
    if not text_to_speak:
        raise HTTPException(status_code=400, detail="text_to_speak í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    if not TTS_CLIENT:
        raise HTTPException(status_code=500, detail="TTS client not initialized")
    try:
        tts_request = texttospeech.SynthesizeSpeechRequest(
            input=texttospeech.SynthesisInput(text=text_to_speak),
            voice=texttospeech.VoiceSelectionParams(language_code="ko-KR", name="ko-KR-Wavenet-A"),
            audio_config=texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3),
        )
        tts_response = await asyncio.to_thread(TTS_CLIENT.synthesize_speech, request=tts_request)
        audio_base64 = base64.b64encode(tts_response.audio_content).decode('utf-8')
        return {"audio": audio_base64}
    except Exception as e:
        print(f"ğŸ’¥ TTS API ì—”ë“œí¬ì¸íŠ¸ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    

# âœ¨âœ¨âœ¨ AR ì´ë¯¸ì§€ ì¸ì‹ì„ ìœ„í•œ ìƒˆë¡œìš´ AI ì¿¼ë¦¬ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€ âœ¨âœ¨âœ¨
@app.post("/api/ar-query")
async def ar_query(image_name: str = Body(..., embed=True)):
    """
    ì¸ì‹ëœ ì´ë¯¸ì§€ ì´ë¦„ì„ ë°›ì•„, í•´ë‹¹ ì´ë¯¸ì§€ì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ
    Geminiê°€ ë™ì ìœ¼ë¡œ ìƒì„±í•œ ì„¤ëª…ê³¼ TTS ì˜¤ë””ì˜¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if MODEL is None:
        return {"error": "Model not initialized"}

    # PDF ì»¨í…ì¸ ì—ì„œ ì´ë¯¸ì§€ ì´ë¦„ìœ¼ë¡œ í•´ë‹¹ í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ ì°¾ê¸°
    context_text = ""
    for page in PDF_CONTENT:
        if image_name in page["images"]:
            context_text = page["text"]
            break
    
    if not context_text:
        return {"error": "Context not found for this image"}

    try:
        # Geminiì—ê²Œ ë™ì  ì„¤ëª…ì„ ìƒì„±í•˜ë„ë¡ ìš”ì²­í•˜ëŠ” í”„ë¡¬í”„íŠ¸
        prompt = f"""
        ë‹¹ì‹ ì€ ì „ë¬¸ ë°•ë¬¼ê´€ ë„ìŠ¨íŠ¸ì…ë‹ˆë‹¤.
        ì•„ë˜ëŠ” í•œ ì „ì‹œë¬¼ì— ëŒ€í•œ ê¸°ë³¸ ì •ë³´ì…ë‹ˆë‹¤. ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì‹¤ì œ ê´€ëŒê°ì—ê²Œ ì„¤ëª…í•˜ë“¯ì´ ìƒìƒí•˜ê³  í¥ë¯¸ë¡œìš´ í•´ì„¤ì„ 1~2 ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ìƒì„±í•´ì£¼ì„¸ìš”.

        --- ê¸°ë³¸ ì •ë³´ ---
        {context_text}
        """
        
        gemini_response = await MODEL.generate_content_async(prompt)
        ai_text = gemini_response.text.strip()

        # ìƒì„±ëœ ì„¤ëª…ìœ¼ë¡œ TTS ì˜¤ë””ì˜¤ ìƒì„±
        tts_request = texttospeech.SynthesizeSpeechRequest(
            input=texttospeech.SynthesisInput(text=ai_text),
            voice=texttospeech.VoiceSelectionParams(language_code="ko-KR", name="ko-KR-Wavenet-A"),
            audio_config=texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3),
        )
        tts_response = await asyncio.to_thread(TTS_CLIENT.synthesize_speech, request=tts_request)
        
        import base64
        audio_base64 = base64.b64encode(tts_response.audio_content).decode('utf-8')

        return {
            "text": ai_text,
            "audio": audio_base64
        }

    except Exception as e:
        print(f"ğŸ’¥ AR ì¿¼ë¦¬ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return {"error": str(e)}    

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    
    if INITIALIZATION_ERROR:
        await websocket.send_json({"type": "error", "data": f"ì„œë²„ ì´ˆê¸°í™” ì‹¤íŒ¨: {INITIALIZATION_ERROR}"})
        await websocket.close(); return
            
    client_id = f"{websocket.client.host}:{websocket.client.port}"
    print(f"âœ… í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ë¨: {client_id}")
    try:
        while True:
            raw_data = await websocket.receive_json()
            message_type = raw_data.get("type"); user_input = raw_data.get("data")
            user_text = ""

            if message_type == "audio":
                audio_bytes = base64.b64decode(user_input)
                stt_request = speech.RecognizeRequest(config=speech.RecognitionConfig(encoding=speech.RecognitionConfig.AudioEncoding.WEBM_OPUS, sample_rate_hertz=SAMPLE_RATE, language_code="ko-KR"), audio=speech.RecognitionAudio(content=audio_bytes))
                stt_response = await asyncio.to_thread(STT_CLIENT.recognize, request=stt_request)
                user_text = stt_response.results[0].alternatives[0].transcript if stt_response.results else ""
                if user_text: await websocket.send_json({"type": "user_text", "data": user_text})
            
            elif message_type == "text":
                user_text = user_input

            if user_text:
                if "ì´ì œ ê·¸ë§Œ" in user_text.strip():
                    ai_text = "ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ì´ìš©í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤."
                    await websocket.send_json({"type": "ai_text", "data": ai_text})
                    # ... (TTS ë° ì¢…ë£Œ ë¡œì§)
                    break
                
                keywords = user_text.split()
                relevant_pages = [p for p in PDF_CONTENT if any(kw.lower() in p["text"].lower() for kw in keywords if len(kw) > 1)] or PDF_CONTENT
                
                prompt_parts = [ "ì•„ë˜ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•´ì¤˜. ì´ë¯¸ì§€ì— ëŒ€í•´ ì–¸ê¸‰í•  ë•ŒëŠ”, ë‚´ê°€ ì•Œë ¤ì¤€ 'ì´ë¯¸ì§€ íŒŒì¼ëª…'ì„ ì‚¬ìš©í•˜ì—¬ `[IMAGE: íŒŒì¼ëª…]` íƒœê·¸ë¥¼ ë‹µë³€ ë§¨ ëì— ë¶™ì—¬ì•¼ í•´. ë‹µë³€ ë³¸ë¬¸ì—ëŠ” íŒŒì¼ëª…ì„ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆ." ]
                for page in relevant_pages[:3]:
                    prompt_parts.append(f"\n--- ì°¸ê³  í…ìŠ¤íŠ¸ (í˜ì´ì§€ {page['page']+1}) ---\n{page['text']}")
                    if page["images"]:
                        for img_file in page["images"]:
                            img_path = IMAGES_DIR / img_file
                            if img_path.exists():
                                try:
                                    prompt_parts.append(f"ì°¸ê³  ì´ë¯¸ì§€ íŒŒì¼ëª…: {img_file}")
                                    prompt_parts.append(Image.open(img_path))
                                except Exception as img_e: print(f"ê²½ê³ : ì´ë¯¸ì§€ ì—´ê¸° ì‹¤íŒ¨ {img_path}: {img_e}")
                
                prompt_parts.append(f"\n--- ì§ˆë¬¸ ---\n{user_text}")

                gemini_response = await MODEL.generate_content_async(prompt_parts)
                ai_text_raw = gemini_response.text
                
                image_tag_match = re.search(r"\[IMAGE:\s*(page_\d+_img_\d+\.\w+)\]", ai_text_raw)
                ai_text = re.sub(r"\[IMAGE:\s*(.*?)\]", "", ai_text_raw).strip()
                await websocket.send_json({"type": "ai_text", "data": ai_text})

                if image_tag_match:
                    image_filename = image_tag_match.group(1).strip()
                    image_url = f"/static/images/{image_filename}"
                    await websocket.send_json({"type": "ai_image", "url": image_url})

                tts_request = texttospeech.SynthesizeSpeechRequest(input=texttospeech.SynthesisInput(text=ai_text), voice=texttospeech.VoiceSelectionParams(language_code="ko-KR", name="ko-KR-Wavenet-A"), audio_config=texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3))
                tts_response = await asyncio.to_thread(TTS_CLIENT.synthesize_speech, request=tts_request)
                if tts_response.audio_content: await websocket.send_bytes(tts_response.audio_content)

    except WebSocketDisconnect: print(f"ğŸ”Œ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ëŠì–´ì§: {client_id}")
    except Exception as e: print(f"ğŸ’¥ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ({client_id}): {e}")
    finally: print(f"ğŸ ì›¹ì†Œì¼“ ì„¸ì…˜ ì¢…ë£Œ: {client_id}")



    # âœ¨âœ¨âœ¨ 4. ìƒˆë¡œìš´ ì´ë¯¸ì§€ ì¸ì‹ API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€ âœ¨âœ¨âœ¨
@app.post("/api/recognize-image")
async def recognize_image(payload: dict = Body(...)):
    user_image_b64 = payload.get("image")
    if not user_image_b64:
        raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    try:
        user_image_bytes = base64.b64decode(user_image_b64.split(',')[1])
        user_image = Image.open(io.BytesIO(user_image_bytes))

        # --- 1ë‹¨ê³„: AIì—ê²Œ ì‚¬ìš©ì ì´ë¯¸ì§€ì— ëŒ€í•œ 'í‚¤ì›Œë“œ' ë¬˜ì‚¬ ìš”ì²­ ---
        describe_prompt = ["ì´ ì´ë¯¸ì§€ì— ë¬´ì—‡ì´ ë³´ì´ëŠ”ì§€ ìƒì„¸í•˜ê²Œ ë¬˜ì‚¬í•´ì¤˜.", user_image]
        
        print("ğŸ¤– Geminiì—ê²Œ ì´ë¯¸ì§€ ë¬˜ì‚¬ ìš”ì²­...")
        describe_response = await MODEL.generate_content_async(describe_prompt)
        query_text = describe_response.text.strip()
        print(f"âœ… ì´ë¯¸ì§€ ë¬˜ì‚¬ ìƒì„±: '{query_text[:30]}...'")

        query_embedding = genai.embed_content(model=EMBEDDING_MODEL, content=query_text, task_type="RETRIEVAL_QUERY")['embedding']

        # --- 3ë‹¨ê³„: ì´ë¯¸ì§€ ë¬˜ì‚¬ ë²¡í„°ì™€ ê°€ì¥ ìœ ì‚¬í•œ PDF í˜ì´ì§€ ë²¡í„° ê²€ìƒ‰ ---
        pdf_embeddings = np.array([page['embedding'] for page in PDF_CONTENT])
        query_vector = np.array(query_embedding)
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        dot_products = np.dot(pdf_embeddings, query_vector)
        norms = np.linalg.norm(pdf_embeddings, axis=1) * np.linalg.norm(query_vector)
        similarity_scores = dot_products / norms
        
        best_match_index = np.argmax(similarity_scores)
        best_match_score = similarity_scores[best_match_index]
        
        print(f"âœ… ê°€ì¥ ìœ ì‚¬í•œ í˜ì´ì§€ ì°¾ìŒ: í˜ì´ì§€ {PDF_CONTENT[best_match_index]['page']} (ìœ ì‚¬ë„: {best_match_score:.2f})")
        
        # íŠ¹ì • ì ìˆ˜ ì´í•˜ì´ë©´ ì¼ì¹˜í•˜ëŠ” ê²°ê³¼ê°€ ì—†ëŠ” ê²ƒìœ¼ë¡œ ê°„ì£¼
        if best_match_score < 0.55:
             return {"status": "no_match", "description": "ì£„ì†¡í•©ë‹ˆë‹¤, ì´ ì´ë¯¸ì§€ì™€ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        context_text = PDF_CONTENT[best_match_index]['text']
        
        # --- 4ë‹¨ê³„: ê²€ìƒ‰ëœ í…ìŠ¤íŠ¸ì˜ ìµœì¢… ìš”ì•½ ìš”ì²­ (ì´ì „ê³¼ ë™ì¼) ---
        summarize_prompt = f"""
        ë‹¹ì‹ ì€ ì „ë¬¸ ë°•ë¬¼ê´€ ë„ìŠ¨íŠ¸ì…ë‹ˆë‹¤. 
        ì•„ë˜ í…ìŠ¤íŠ¸ëŠ” í•˜ë‚˜ì˜ íŠ¹ì • ì „ì‹œë¬¼ì— ëŒ€í•œ ì •ë³´ì…ë‹ˆë‹¤. 
        ì´ í…ìŠ¤íŠ¸ì˜ í•µì‹¬ ë‚´ìš©ë§Œì„ ë°”íƒ•ìœ¼ë¡œ, ì‹¤ì œ ê´€ëŒê°ì—ê²Œ ì„¤ëª…í•˜ë“¯ì´ ìƒìƒí•˜ê³  í¥ë¯¸ë¡œìš´ í•´ì„¤ì„ ìƒì„±í•´ì£¼ì„¸ìš”. 
        "ì•ˆë…•í•˜ì„¸ìš”" ì™€ ê°™ì€ ì¸ì‚¬ë§ì€ ì‚¬ìš©í•˜ì§€ ë§ê³ , "ì´ê²ƒì€..." ê³¼ ê°™ì´ ë°”ë¡œ ì„¤ëª…ìœ¼ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.
        --- ì›ë³¸ í…ìŠ¤íŠ¸ ---
        {context_text}
        """
        print(f"ğŸ¤– Geminiì—ê²Œ í…ìŠ¤íŠ¸ ìš”ì•½ ìš”ì²­...")
        summarize_response = await MODEL.generate_content_async(summarize_prompt)
        final_description = summarize_response.text.strip()
        
        return {"status": "success", "description": final_description}
    
    except Exception as e:
        print(f"ğŸ’¥ ì´ë¯¸ì§€ ì¸ì‹/ìš”ì•½ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))
