# main.py (0812 ì˜¤í›„ 12ì‹œ 08ë¶„ ìµœì¢… ì™„ì„± ë° í†µí•© ë²„ì „)

import asyncio
import os
import re
import json
#--- import time ---
import shutil
import base64
import io
from pathlib import Path
from contextlib import asynccontextmanager

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Body, HTTPException
from fastapi.responses import FileResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from PIL import Image
import fitz  # PyMuPDF
import numpy as np # ë²¡í„° ê³„ì‚°ì„ ìœ„í•´ ì¶”ê°€

import google.generativeai as genai
from google.cloud import speech, texttospeech


# --- 1. ì„¤ì • ---
KNOWLEDGE_PDF_PATH = "knowledge.pdf"
IMAGES_DIR = Path(__file__).resolve().parent / "static" / "images"
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
MAX_OUTPUT_TOKENS = 1500
STT_CREDENTIALS_PATH = "/etc/secrets/voice-chat-462608-412b0459f610.json"
TTS_CREDENTIALS_PATH = "/etc/secrets/voice-chat-462608-e445e48514e2.json"
SAMPLE_RATE = 48000
EMBEDDING_MODEL = "models/text-embedding-004"

# --- 2. ì „ì—­ ë³€ìˆ˜ ë° ì•± ì´ˆê¸°í™” ---
app = FastAPI()
PDF_CONTENT = []
MODEL, STT_CLIENT, TTS_CLIENT = None, None, None
INITIALIZATION_ERROR = None

# --- 3. Lifespanì„ ì´ìš©í•œ ì•ˆì •ì ì¸ ì•± ì´ˆê¸°í™” ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    global MODEL, STT_CLIENT, TTS_CLIENT, PDF_CONTENT, INITIALIZATION_ERROR, EMBEDDING_MODEL, KNOWLEDGE_CONTEXT
    print("âœ¨ ì•± ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

    try:
        if IMAGES_DIR.exists(): shutil.rmtree(IMAGES_DIR)
        # PDF ì²˜ë¦¬ ë¡œì§
        IMAGES_DIR.mkdir(parents=True, exist_ok=True)
        
        pdf_path = Path(__file__).resolve().parent / KNOWLEDGE_PDF_PATH
        if not pdf_path.exists(): raise FileNotFoundError(f"{pdf_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        doc = fitz.open(pdf_path)
        content_list = []

        for page_num, page in enumerate(doc):
            page = doc.load_page(page_num) # í˜ì´ì§€ë¥¼ ë²ˆí˜¸ë¡œ ëª…ì‹œí•˜ì—¬ ë¡œë“œ
            
            page_text = page.get_text("text")
            page_images = page.get_images(full=True)

            page_data = {"page": page_num, "text": page_text, "images": []}
           
            
            for img_index, img in enumerate(page_images):
                xref = img[0]
                base_image = doc.extract_image(xref)
                image_bytes = base_image["image"]
                try:
                    image_obj = Image.open(io.BytesIO(image_bytes))
                    image_filename = f"page_{page_num}_img_{img_index}.png"
                    image_obj.save(IMAGES_DIR / image_filename, "PNG")
                    page_data["images"].append(image_filename)
                except Exception as img_e:
                    print(f"ê²½ê³ : ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨ (í˜ì´ì§€ {page_num}): {img_e}")

            content_list.append(page_data)

        PDF_CONTENT = content_list
        KNOWLEDGE_CONTEXT = "\n\n".join([page['text'] for page in content_list]) # ì „ì²´ í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ ìƒì„±

        print(f"âœ… PDF ì²˜ë¦¬ ì™„ë£Œ: {len(doc)} í˜ì´ì§€, {sum(len(p['images']) for p in PDF_CONTENT)}ê°œ ì´ë¯¸ì§€ ì¶”ì¶œ")

        # PDF í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì„ë² ë”© ë²¡í„° ìƒì„±
        texts_to_embed = [page['text'] for page in PDF_CONTENT if page['text'].strip()]
        if texts_to_embed:
            embedding_response = genai.embed_content(model=EMBEDDING_MODEL, content=texts_to_embed, task_type="RETRIEVAL_DOCUMENT")
            text_index = 0
            for i, page_data in enumerate(PDF_CONTENT):
                if page_data['text'].strip():
                    page_data['embedding'] = embedding_response['embedding'][text_index]
                    text_index += 1
            print(f"âœ… {len(texts_to_embed)}ê°œ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì„ë² ë”© ìƒì„± ì™„ë£Œ.")


        # API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        STT_CLIENT = speech.SpeechClient.from_service_account_file(STT_CREDENTIALS_PATH)
        TTS_CLIENT = texttospeech.TextToSpeechClient.from_service_account_file(TTS_CREDENTIALS_PATH)
        if not GEMINI_API_KEY: raise Exception("GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        genai.configure(api_key=GEMINI_API_KEY)
        
        system_instruction = f"""
            ë‹¹ì‹ ì€ ì „ë¬¸ ë„ìŠ¨íŠ¸ì…ë‹ˆë‹¤. 
            ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´, ë°˜ë“œì‹œ ì•„ë˜ ì œê³µëœ 'ì§€ì‹ ë² ì´ìŠ¤' ë‚´ìš©ë§Œì„ ê·¼ê±°ë¡œ í•´ì•¼ í•©ë‹ˆë‹¤.
            ë‹¹ì‹ ì˜ ì¼ë°˜ ì§€ì‹ì„ ì‚¬ìš©í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤. 'ì§€ì‹ ë² ì´ìŠ¤'ì— ë‚´ìš©ì´ ì—†ë‹¤ë©´ "ì œê°€ ê°€ì§„ ì •ë³´ë¡œëŠ” ë‹µë³€í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤."ë¼ê³  ì†”ì§í•˜ê²Œ ë§í•´ì•¼ í•©ë‹ˆë‹¤.
                        
            âœ¨âœ¨âœ¨ [ì¤‘ìš” ê·œì¹™] âœ¨âœ¨âœ¨
                1. ëª¨ë“  ë‹µë³€ì€ ë°˜ë“œì‹œ 2000ì ì´ë‚´ë¡œ, í•µì‹¬ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì„œ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.
                2. ë‹µë³€ì´ ê¸¸ì–´ì§ˆ ê²½ìš°, ê°€ì¥ ì¤‘ìš”í•œ ì •ë³´ë¶€í„° ìˆœì„œëŒ€ë¡œ, ìµœëŒ€ 3~4ê°œì˜ ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
                3. ë§Œì•½ ì‚¬ìš©ìê°€ "ì–´ë–»ê²Œ ìƒê²¼ì–´", "ë³´ì—¬ì¤˜", "ê·¸ë¦¼", "ì‚¬ì§„" ë“± ì‹œê°ì ì¸ ì •ë³´ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ìš”êµ¬í•˜ê³ , í•´ë‹¹ ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ ìˆëŠ” ì´ë¯¸ì§€ê°€ ìˆë‹¤ë©´ ë‹µë³€ ëì— `[SHOW_IMAGE:ì´ë¯¸ì§€íŒŒì¼ëª…]` íƒœê·¸ë¥¼ ë¶™ì—¬ì£¼ì„¸ìš”.
                4. ì¼ë°˜ì ì¸ ì§ˆë¬¸ì—ëŠ” ì ˆëŒ€ `[SHOW_IMAGE]` íƒœê·¸ë¥¼ ë¶™ì´ë©´ ì•ˆ ë©ë‹ˆë‹¤.

         --- ì§€ì‹ ë² ì´ìŠ¤ ---
        {KNOWLEDGE_CONTEXT}
               
        """
        
        generation_config = genai.GenerationConfig(max_output_tokens=MAX_OUTPUT_TOKENS)
        MODEL = genai.GenerativeModel('gemini-1.5-flash', system_instruction=system_instruction, generation_config=generation_config)
        
        print("ğŸ‰ ëª¨ë“  ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ. ì±—ë´‡ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        INITIALIZATION_ERROR = f"[{type(e).__name__}] {e}"
        print(f"ğŸ’¥ FATAL: ì•± ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ! ì›ì¸: {INITIALIZATION_ERROR}")

    yield # ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
    
    print("ğŸ‘‹ ì„œë²„ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")

app = FastAPI(lifespan=lifespan)

# --- 4. í—¬í¼ í•¨ìˆ˜ ---
def find_best_page_by_vector(query_text: str):
    """ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì™€ ê°€ì¥ ìœ ì‚¬í•œ PDF í˜ì´ì§€ë¥¼ ì‹œë§¨í‹± ê²€ìƒ‰ìœ¼ë¡œ ì°¾ìŠµë‹ˆë‹¤."""
    if not query_text or not any('embedding' in p for p in PDF_CONTENT): return None
    
    query_embedding = genai.embed_content(model=EMBEDDING_MODEL, content=query_text, task_type="RETRIEVAL_QUERY")['embedding']
    
    pdf_embeddings = np.array([page['embedding'] for page in PDF_CONTENT if 'embedding' in page])
    query_vector = np.array(query_embedding)
    
    dot_products = np.dot(pdf_embeddings, query_vector)
    norms = np.linalg.norm(pdf_embeddings, axis=1) * np.linalg.norm(query_vector)
    similarity_scores = dot_products / norms
    
    best_match_index = np.argmax(similarity_scores)
    return PDF_CONTENT[best_match_index] if similarity_scores[best_match_index] > 0.6 else None


# --- 4. FastAPI ì—”ë“œí¬ì¸íŠ¸ ---
BASE_DIR = Path(__file__).resolve().parent
app.mount("/static", StaticFiles(directory=BASE_DIR / "static"), name="static")

@app.get("/", response_class=FileResponse)
async def read_index(): return FileResponse(BASE_DIR / "static" / "index.html")

# âœ¨âœ¨âœ¨ /ar ê²½ë¡œ ì¶”ê°€ âœ¨âœ¨âœ¨
@app.get("/ar", response_class=FileResponse)
async def read_ar_page():
    return FileResponse(BASE_DIR / "static" / "ar.html")

@app.get("/api/pdf-content")
async def get_pdf_content():
    if INITIALIZATION_ERROR or not PDF_CONTENT:
        # ì´ˆê¸°í™” ì‹¤íŒ¨ ë˜ëŠ” ì»¨í…ì¸ ê°€ ì—†ëŠ” ê²½ìš° ëª…í™•í•œ ì˜¤ë¥˜ ë°˜í™˜
        return JSONResponse(
            status_code=500, 
            content={"error": "PDF content not loaded or initialization failed."}
        )
    
    # âœ¨ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ, ì›ë³¸ ë°°ì—´ êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •
    return JSONResponse(content=PDF_CONTENT)

@app.post("/api/tts")
async def text_to_speech_api(payload: dict = Body(...)):
    # âœ¨ 1. ìŒì„± ì•ˆë‚´ ë²„íŠ¼ ì˜¤ë¥˜ ìˆ˜ì •ì„ ìœ„í•œ ìµœì¢… TTS API ì½”ë“œ
    text_to_speak = payload.get("text_to_speak")
    if not text_to_speak:
        raise HTTPException(status_code=400, detail="text_to_speak í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    if not TTS_CLIENT:
        raise HTTPException(status_code=500, detail="TTS client not initialized")
    try:
        tts_request = texttospeech.SynthesizeSpeechRequest(
            input=texttospeech.SynthesisInput(text=text_to_speak),
            voice=texttospeech.VoiceSelectionParams(language_code="ko-KR", name="ko-KR-Wavenet-A"),
            audio_config=texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3),
        )
        tts_response = await asyncio.to_thread(TTS_CLIENT.synthesize_speech, request=tts_request)
        audio_base64 = base64.b64encode(tts_response.audio_content).decode('utf-8')
        return {"audio": audio_base64}
    except Exception as e:
        print(f"ğŸ’¥ TTS API ì—”ë“œí¬ì¸íŠ¸ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    

# âœ¨âœ¨âœ¨ AR ì´ë¯¸ì§€ ì¸ì‹ì„ ìœ„í•œ ìƒˆë¡œìš´ AI ì¿¼ë¦¬ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€ âœ¨âœ¨âœ¨
@app.post("/api/ar-query")
async def ar_query(image_name: str = Body(..., embed=True)):
    """
    ì¸ì‹ëœ ì´ë¯¸ì§€ ì´ë¦„ì„ ë°›ì•„, í•´ë‹¹ ì´ë¯¸ì§€ì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ
    Geminiê°€ ë™ì ìœ¼ë¡œ ìƒì„±í•œ ì„¤ëª…ê³¼ TTS ì˜¤ë””ì˜¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if MODEL is None:
        return {"error": "Model not initialized"}

    # PDF ì»¨í…ì¸ ì—ì„œ ì´ë¯¸ì§€ ì´ë¦„ìœ¼ë¡œ í•´ë‹¹ í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ ì°¾ê¸°
    context_text = ""
    for page in PDF_CONTENT:
        if image_name in page["images"]:
            context_text = page["text"]
            break
    
    if not context_text:
        return {"error": "Context not found for this image"}

    try:
        # Geminiì—ê²Œ ë™ì  ì„¤ëª…ì„ ìƒì„±í•˜ë„ë¡ ìš”ì²­í•˜ëŠ” í”„ë¡¬í”„íŠ¸
        prompt = f"""
        ë‹¹ì‹ ì€ ì „ë¬¸ ë°•ë¬¼ê´€ ë„ìŠ¨íŠ¸ì…ë‹ˆë‹¤.
        ì•„ë˜ëŠ” í•œ ì „ì‹œë¬¼ì— ëŒ€í•œ ê¸°ë³¸ ì •ë³´ì…ë‹ˆë‹¤. ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì‹¤ì œ ê´€ëŒê°ì—ê²Œ ì„¤ëª…í•˜ë“¯ì´ ìƒìƒí•˜ê³  í¥ë¯¸ë¡œìš´ í•´ì„¤ì„ 1~2 ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ìƒì„±í•´ì£¼ì„¸ìš”.

        --- ê¸°ë³¸ ì •ë³´ ---
        {context_text}
        """
        
        gemini_response = await MODEL.generate_content_async(prompt)
        ai_text = gemini_response.text.strip()

        # ìƒì„±ëœ ì„¤ëª…ìœ¼ë¡œ TTS ì˜¤ë””ì˜¤ ìƒì„±
        tts_request = texttospeech.SynthesizeSpeechRequest(
            input=texttospeech.SynthesisInput(text=ai_text),
            voice=texttospeech.VoiceSelectionParams(language_code="ko-KR", name="ko-KR-Wavenet-A"),
            audio_config=texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3),
        )
        tts_response = await asyncio.to_thread(TTS_CLIENT.synthesize_speech, request=tts_request)
        
        import base64
        audio_base64 = base64.b64encode(tts_response.audio_content).decode('utf-8')

        return {
            "text": ai_text,
            "audio": audio_base64
        }

    except Exception as e:
        print(f"ğŸ’¥ AR ì¿¼ë¦¬ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return {"error": str(e)}    

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    
    if INITIALIZATION_ERROR:
        await websocket.send_json({"type": "error", "data": f"ì„œë²„ ì´ˆê¸°í™” ì‹¤íŒ¨: {INITIALIZATION_ERROR}"})
        await websocket.close(); return
            
    client_id = f"{websocket.client.host}:{websocket.client.port}"
    print(f"âœ… í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ë¨: {client_id}")
    try:
        while True:
            raw_data = await websocket.receive_json()
            message_type = raw_data.get("type"); 
            user_input = raw_data.get("data")
            user_text = ""

            if message_type == "audio":
                import base64
                audio_bytes = base64.b64decode(user_input)
                stt_request = speech.RecognizeRequest(config=speech.RecognitionConfig(encoding=speech.RecognitionConfig.AudioEncoding.WEBM_OPUS, sample_rate_hertz=SAMPLE_RATE, language_code="ko-KR"), audio=speech.RecognitionAudio(content=audio_bytes))
                stt_response = await asyncio.to_thread(STT_CLIENT.recognize, request=stt_request)
                user_text = stt_response.results[0].alternatives[0].transcript if stt_response.results else ""
                if user_text: await websocket.send_json({"type": "user_text", "data": user_text})
            
            elif message_type == "text":
                user_text = user_input

            if user_text:
                print(f"ğŸ‘¤ ì‚¬ìš©ì ({client_id}): {user_text}")

                if "ì´ì œ ê·¸ë§Œ" in user_text.strip():
                    ai_text = "ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ì´ìš©í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤."
                    await websocket.send_json({"type": "ai_text", "data": ai_text})
                    # ... (TTS ë° ì¢…ë£Œ ë¡œì§)
                    break
                
                 # --- âœ¨ 2. ë°±ì—”ë“œê°€ ì§ì ‘ ì´ë¯¸ì§€ í‘œì‹œ ì˜ë„ íŒŒì•… (í•µì‹¬ ìˆ˜ì •) ---
                image_keywords = ["ë³´ì—¬ì¤˜", "ì‚¬ì§„", "ê·¸ë¦¼", "ì´ë¯¸ì§€", "ìƒê¹€ìƒˆ", "ëª¨ìŠµ"]
                show_image_intent = any(keyword in user_text for keyword in image_keywords)

                keywords = re.findall(r'[\wê°€-í£]{2,}', user_text)
                best_match = {"score": 0, "page_data": None}
                for page in PDF_CONTENT:
                    score = sum(1 for keyword in keywords if keyword.lower() in page["text"].lower())
                    if score > best_match["score"]:
                        best_match["score"] = score
                        best_match["page_data"] = page
                
                context_text = "\n\n".join([p['text'] for p in PDF_CONTENT]) # ê¸°ë³¸ì€ ì „ì²´ ì»¨í…ìŠ¤íŠ¸
 
                context_images = []

                if best_match["page_data"]:
                    context_text = best_match["page_data"]["text"]
                    context_images = best_match["page_data"]["images"]
                    print(f"âœ… ì»¨í…ìŠ¤íŠ¸ ì°¾ìŒ: í˜ì´ì§€ {best_match['page_data']['page']} (ì ìˆ˜: {best_match['score']})")
 

                # --- 3. AIì—ê²Œ ì´ë¯¸ì§€ í‘œì‹œ ì—¬ë¶€ë¥¼ ìŠ¤ìŠ¤ë¡œ ê²°ì •í•˜ë„ë¡ ì§€ì‹œ ---
                # ì»¨í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ ëª©ë¡ì€ ì´ì œ í•„ìš” ì—†ìœ¼ë¯€ë¡œ í”„ë¡¬í”„íŠ¸ì—ì„œ ì œì™¸í•©ë‹ˆë‹¤.
            
                prompt = f"""ì•„ë˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì¤˜.
                
                --- ì»¨í…ìŠ¤íŠ¸ ---
                {context_text}
                
                --- ì§ˆë¬¸ ---
                {user_text}
                
                               
                """
                
                gemini_response = await MODEL.generate_content_async(prompt)
                ai_text = gemini_response.text.strip()
                await websocket.send_json({"type": "ai_text", "data": ai_text})

                 # --- 5. ì˜ë„(Intent)ì— ë”°ë¼ ì´ë¯¸ì§€ í‘œì‹œ ---
                if show_image_intent and best_match["page_data"] and best_match["page_data"]["images"]:
                    # ê²€ìƒ‰ëœ ê°€ì¥ ì •í™•í•œ í˜ì´ì§€ì˜ ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë¥¼ ì „ì†¡
                    image_filename = best_match["page_data"]["images"][0]
                    image_url = f"/static/images/{image_filename}"
                    print(f"ğŸ–¼ï¸ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì´ë¯¸ì§€ í‘œì‹œ ìš”ì²­: {image_url}")
                    await websocket.send_json({"type": "ai_image", "data": {"url": image_url}})

              
                tts_request = texttospeech.SynthesizeSpeechRequest(input=texttospeech.SynthesisInput(text=ai_text), voice=texttospeech.VoiceSelectionParams(language_code="ko-KR", name="ko-KR-Wavenet-A"), audio_config=texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3))
                tts_response = await asyncio.to_thread(TTS_CLIENT.synthesize_speech, request=tts_request)
                if tts_response.audio_content: await websocket.send_bytes(tts_response.audio_content)

    except WebSocketDisconnect: print(f"ğŸ”Œ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ëŠì–´ì§: {client_id}")
    except Exception as e: print(f"ğŸ’¥ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ({client_id}): {e}")
    finally: print(f"ğŸ ì›¹ì†Œì¼“ ì„¸ì…˜ ì¢…ë£Œ: {client_id}")



    # âœ¨âœ¨âœ¨ 4. ìƒˆë¡œìš´ ì´ë¯¸ì§€ ì¸ì‹ API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€ âœ¨âœ¨âœ¨
@app.post("/api/recognize-image")
async def recognize_image(payload: dict = Body(...)):
    user_image_b64 = payload.get("image")
    if not user_image_b64:
        raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    try:
        user_image_bytes = base64.b64decode(user_image_b64.split(',')[1])
        user_image = Image.open(io.BytesIO(user_image_bytes))

        # 1. AIì—ê²Œ ì´ë¯¸ì§€ ë¬˜ì‚¬ ìš”ì²­ (ë¹ ë¥¸ ì‘ì—…)
        describe_prompt = ["ì´ ì´ë¯¸ì§€ì— ë³´ì´ëŠ” ì‚¬ë¬¼ì´ë‚˜ ì¥ì†Œì˜ ì´ë¦„ì„ í¬í•¨í•˜ì—¬ ê°„ê²°í•˜ê²Œ ë¬˜ì‚¬í•´ì¤˜.", user_image]
        describe_response = await MODEL.generate_content_async(describe_prompt)
        image_description = describe_response.text.strip()
        
        # 2. ë¬˜ì‚¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°€ì¥ ê´€ë ¨ìˆëŠ” í˜ì´ì§€ë¥¼ ì‹œë§¨í‹± ê²€ìƒ‰
        best_page = find_best_page_by_vector(image_description)
        if not best_page:
            return {"status": "no_match", "description": "ì£„ì†¡í•©ë‹ˆë‹¤, ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        
        context_text = best_page["text"]
        
        # 3. ì°¾ì€ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… í•´ì„¤ ìƒì„± (ë¶ˆí•„ìš”í•œ íƒœê·¸ ê·œì¹™ ì œê±°)
        summarize_prompt = f"""ë‹¹ì‹ ì€ ì „ë¬¸ ë„ìŠ¨íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì‹¤ì œ ê´€ëŒê°ì—ê²Œ ì„¤ëª…í•˜ë“¯ì´ ìƒìƒí•˜ê³  í¥ë¯¸ë¡œìš´ í•´ì„¤ì„ ìƒì„±í•´ì£¼ì„¸ìš”. ì¸ì‚¬ë§ ì—†ì´ ë°”ë¡œ ì„¤ëª…ìœ¼ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤. --- ì›ë³¸ í…ìŠ¤íŠ¸ --- {context_text}"""
        summarize_response = await MODEL.generate_content_async(summarize_prompt)
        final_description = summarize_response.text.strip()
        
        return {"status": "success", "description": final_description}

    
    except Exception as e:
        print(f"ğŸ’¥ ì´ë¯¸ì§€ ì¸ì‹/ìš”ì•½ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))